{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3300343",
   "metadata": {},
   "source": [
    "## Document Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4876019f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdc3c866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    api_version=\"2024-10-21\",\n",
    "    azure_deployment=\"text-embedding-ada-002\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bea84230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.005540425889194012,\n",
       " 0.0047363233752548695,\n",
       " -0.015009919181466103,\n",
       " -0.027093535289168358,\n",
       " -0.015173893421888351,\n",
       " 0.015173893421888351,\n",
       " -0.0176082756370306,\n",
       " 0.009554633870720863,\n",
       " -0.00942219328135252,\n",
       " -0.030801868066191673,\n",
       " 0.02631150558590889,\n",
       " 0.011169145815074444,\n",
       " -0.023397814482450485,\n",
       " -0.009510486386716366,\n",
       " 0.007700467016547918,\n",
       " 0.010450183413922787,\n",
       " 0.027572842314839363,\n",
       " -0.012581843882799149,\n",
       " 0.012783657759428024,\n",
       " 0.014845944941043854,\n",
       " -0.007164398208260536,\n",
       " -0.003342545125633478,\n",
       " 0.0026251592207700014,\n",
       " 0.007183318492025137,\n",
       " -0.019777776673436165,\n",
       " -0.003979520406574011,\n",
       " 0.010633077472448349,\n",
       " -0.017456915229558945,\n",
       " 0.0280773788690567,\n",
       " -0.030928000807762146,\n",
       " 0.003411918645724654,\n",
       " -0.006385522428900003,\n",
       " -0.007643706630915403,\n",
       " -0.019626416265964508,\n",
       " 0.00947895273566246,\n",
       " -0.01697760634124279,\n",
       " 0.002305094851180911,\n",
       " -0.013332339935004711,\n",
       " 0.020067883655428886,\n",
       " -0.017847929149866104,\n",
       " 0.007240078877657652,\n",
       " 0.009636620059609413,\n",
       " 0.012178216129541397,\n",
       " -0.022590558975934982,\n",
       " -0.03299659490585327,\n",
       " 0.010809664614498615,\n",
       " 0.0024517253041267395,\n",
       " -0.008911351673305035,\n",
       " -0.002087513916194439,\n",
       " 0.02890986204147339,\n",
       " 0.028279192745685577,\n",
       " 0.0021127406507730484,\n",
       " -0.017128966748714447,\n",
       " 0.015287413261830807,\n",
       " -0.016044216230511665,\n",
       " 0.008955498225986958,\n",
       " -0.03163434937596321,\n",
       " 0.0280773788690567,\n",
       " 0.02790079079568386,\n",
       " -0.021076953038573265,\n",
       " -0.000825387891381979,\n",
       " 0.004856150131672621,\n",
       " -0.006584182847291231,\n",
       " 0.003654726082459092,\n",
       " 0.009491566568613052,\n",
       " 0.01511082611978054,\n",
       " 0.003724099602550268,\n",
       " 0.00755541305989027,\n",
       " -0.01657397858798504,\n",
       " 0.01878131926059723,\n",
       " 0.019613802433013916,\n",
       " 0.009554633870720863,\n",
       " -0.003474985482171178,\n",
       " -0.007523879874497652,\n",
       " 0.018718251958489418,\n",
       " -0.0005597186391241848,\n",
       " -0.017583047971129417,\n",
       " 0.0007646860321983695,\n",
       " 0.006095414515584707,\n",
       " 0.0029073834884911776,\n",
       " 0.03549404442310333,\n",
       " -0.02603401057422161,\n",
       " -0.009485259652137756,\n",
       " 0.015363093465566635,\n",
       " 0.02077423222362995,\n",
       " 0.0036421127151697874,\n",
       " -0.0030492839869111776,\n",
       " 0.020004816353321075,\n",
       " -0.015981148928403854,\n",
       " -0.02444472536444664,\n",
       " 0.012033161707222462,\n",
       " 0.014959465712308884,\n",
       " 0.009132085368037224,\n",
       " 0.009712300263345242,\n",
       " -0.012884564697742462,\n",
       " 0.0003496270510368049,\n",
       " -0.007902281358838081,\n",
       " 0.017696568742394447,\n",
       " 0.003903840435668826,\n",
       " -0.04760288819670677,\n",
       " -0.01411436963826418,\n",
       " 0.00015096635615918785,\n",
       " -0.017696568742394447,\n",
       " -0.014177436009049416,\n",
       " -0.00970599427819252,\n",
       " -0.005275545176118612,\n",
       " -0.007391439285129309,\n",
       " 0.00031178692006506026,\n",
       " 0.02319600060582161,\n",
       " 0.0009286599233746529,\n",
       " -0.010002408176660538,\n",
       " 0.015943309292197227,\n",
       " -0.01788576878607273,\n",
       " -0.03413179889321327,\n",
       " 0.005594032816588879,\n",
       " -0.005048504564911127,\n",
       " 0.006164788268506527,\n",
       " -0.006224701646715403,\n",
       " -0.019891295582056046,\n",
       " -0.023296907544136047,\n",
       " 0.013773808255791664,\n",
       " 0.036023806780576706,\n",
       " 0.017267713323235512,\n",
       " -0.025226755067706108,\n",
       " 0.007757227402180433,\n",
       " 0.008097788318991661,\n",
       " -0.04210345447063446,\n",
       " -0.014467543922364712,\n",
       " -0.005414292216300964,\n",
       " -0.012304349802434444,\n",
       " 0.043490923941135406,\n",
       " 0.005622413009405136,\n",
       " 0.013168365694582462,\n",
       " -0.01033035572618246,\n",
       " -0.029237808659672737,\n",
       " 0.016107283532619476,\n",
       " -0.007309452164918184,\n",
       " 0.027068307623267174,\n",
       " -0.011907028034329414,\n",
       " -0.01765872910618782,\n",
       " 0.0028222431428730488,\n",
       " 0.027572842314839363,\n",
       " 0.018365077674388885,\n",
       " -0.013281886465847492,\n",
       " -0.0029988305177539587,\n",
       " 0.001986606977880001,\n",
       " 0.003903840435668826,\n",
       " -0.02246442623436451,\n",
       " 0.009724914096295834,\n",
       " -0.01845337077975273,\n",
       " 0.011585387401282787,\n",
       " 0.02139228768646717,\n",
       " -0.0011312622809782624,\n",
       " 0.00407412089407444,\n",
       " 0.013281886465847492,\n",
       " 0.012443097308278084,\n",
       " -0.001858896459452808,\n",
       " 0.027371028438210487,\n",
       " 0.008526642806828022,\n",
       " -0.005341765470802784,\n",
       " 0.006048114504665136,\n",
       " 0.00323217804543674,\n",
       " -0.0040552010759711266,\n",
       " -0.03736082464456558,\n",
       " 0.012846725061535835,\n",
       " 0.02822873927652836,\n",
       " 0.029237808659672737,\n",
       " -0.0069184377789497375,\n",
       " 0.00033464867738075554,\n",
       " -0.027244895696640015,\n",
       " -0.012499856762588024,\n",
       " 0.010059168562293053,\n",
       " -0.0373355969786644,\n",
       " 0.01975254900753498,\n",
       " -0.016145123168826103,\n",
       " 0.005039044190198183,\n",
       " -0.0038660001009702682,\n",
       " 0.022880665957927704,\n",
       " -0.01347108744084835,\n",
       " -0.014833332039415836,\n",
       " -0.031886618584394455,\n",
       " 0.014845944941043854,\n",
       " 0.005360685288906097,\n",
       " 0.024797899648547173,\n",
       " 0.006956277880817652,\n",
       " 0.0011832924792543054,\n",
       " 0.01403868943452835,\n",
       " -0.005203018430620432,\n",
       " 0.0031123508233577013,\n",
       " -0.020357990637421608,\n",
       " 0.015236959792673588,\n",
       " 0.028026925399899483,\n",
       " 0.03218933939933777,\n",
       " 0.008589710108935833,\n",
       " -0.6861677169799805,\n",
       " -0.00973122101277113,\n",
       " 0.01822633109986782,\n",
       " 0.0209382064640522,\n",
       " 0.015400934033095837,\n",
       " 0.007996881380677223,\n",
       " 0.014076529070734978,\n",
       " 0.029742343351244926,\n",
       " 0.005433212500065565,\n",
       " 0.032391153275966644,\n",
       " -0.012424176558852196,\n",
       " 0.020950820297002792,\n",
       " -0.00854556355625391,\n",
       " -0.007820294238626957,\n",
       " -0.005556192714720964,\n",
       " -0.007826601155102253,\n",
       " 0.00235554832033813,\n",
       " -0.02426813915371895,\n",
       " -0.020067883655428886,\n",
       " 0.01738123409450054,\n",
       " -0.0012912944657728076,\n",
       " 0.030700961127877235,\n",
       " -0.02110218070447445,\n",
       " -0.013988235965371132,\n",
       " 0.006205781828612089,\n",
       " 0.006779690273106098,\n",
       " 0.007883360609412193,\n",
       " -0.007290532346814871,\n",
       " -0.01675056479871273,\n",
       " 0.025327662006020546,\n",
       " -0.008614936843514442,\n",
       " 0.020042655989527702,\n",
       " -0.0023066713474690914,\n",
       " 0.0026566926389932632,\n",
       " 0.06967629492282867,\n",
       " 0.02139228768646717,\n",
       " -0.0020938205998390913,\n",
       " 0.01895790547132492,\n",
       " 0.0019818770233541727,\n",
       " 0.03112981654703617,\n",
       " -0.011862881481647491,\n",
       " -0.013912555761635303,\n",
       " 0.001475765137001872,\n",
       " -0.017267713323235512,\n",
       " 0.004982284270226955,\n",
       " 0.009239299222826958,\n",
       " 0.010815971530973911,\n",
       " -0.004269628319889307,\n",
       " -0.0009113165433518589,\n",
       " 0.010639384388923645,\n",
       " 0.02438165806233883,\n",
       " -0.014354023151099682,\n",
       " 0.01879393309354782,\n",
       " 0.015829788520932198,\n",
       " 0.0011438756482675672,\n",
       " 0.010021327994763851,\n",
       " 0.016838859766721725,\n",
       " 0.010267289355397224,\n",
       " -0.002582588931545615,\n",
       " 0.0033961518201977015,\n",
       " 0.0012140375329181552,\n",
       " 0.021354448050260544,\n",
       " -0.005606646183878183,\n",
       " 0.0008892430923879147,\n",
       " -0.011787201277911663,\n",
       " 0.025378115475177765,\n",
       " -0.023473495617508888,\n",
       " 0.006300381850451231,\n",
       " -0.005480512510985136,\n",
       " -0.01055739726871252,\n",
       " 0.0005955879460088909,\n",
       " -0.003091854276135564,\n",
       " -0.02025708369910717,\n",
       " -0.014429704286158085,\n",
       " 0.019702095538377762,\n",
       " 0.033248864114284515,\n",
       " 0.0057548535987734795,\n",
       " -0.01248093694448471,\n",
       " -0.013773808255791664,\n",
       " 0.020219244062900543,\n",
       " 0.011818734928965569,\n",
       " 0.003925913944840431,\n",
       " -0.020635485649108887,\n",
       " -0.02556731551885605,\n",
       " 0.01900836080312729,\n",
       " -0.01623341627418995,\n",
       " -0.03342545032501221,\n",
       " -0.013117912225425243,\n",
       " -0.0011194372782483697,\n",
       " 0.005477359052747488,\n",
       " 0.029742343351244926,\n",
       " 0.002003950299695134,\n",
       " -0.009535713121294975,\n",
       " -0.01839030534029007,\n",
       " 0.026185370981693268,\n",
       " -0.003333084983751178,\n",
       " -0.009907808154821396,\n",
       " 0.00899964477866888,\n",
       " 0.025088008493185043,\n",
       " 0.003534899093210697,\n",
       " 0.0069121308624744415,\n",
       " 0.005521506071090698,\n",
       " 0.0033772317692637444,\n",
       " 0.008381589315831661,\n",
       " 0.017053285613656044,\n",
       " -0.011043012142181396,\n",
       " 0.0038407733663916588,\n",
       " 0.022678852081298828,\n",
       " 0.020812073722481728,\n",
       " -0.020496739074587822,\n",
       " 0.007252692244946957,\n",
       " 0.0012203442165628076,\n",
       " -0.034888602793216705,\n",
       " 0.022325677797198296,\n",
       " 0.011396186426281929,\n",
       " -0.02868282049894333,\n",
       " -0.001720149302855134,\n",
       " 0.018920065835118294,\n",
       " 0.020837299525737762,\n",
       " -0.01680101826786995,\n",
       " 0.019109267741441727,\n",
       " -0.002019717125222087,\n",
       " 0.018743479624390602,\n",
       " 0.003525438951328397,\n",
       " 0.002965720370411873,\n",
       " 0.008633856661617756,\n",
       " -0.005029584281146526,\n",
       " 0.0064706625416874886,\n",
       " -0.003195914439857006,\n",
       " -0.00928344577550888,\n",
       " 0.027799883857369423,\n",
       " -0.003620039438828826,\n",
       " 0.009359125979244709,\n",
       " -0.004108807537704706,\n",
       " 0.003780859988182783,\n",
       " -0.0030319406650960445,\n",
       " 0.006158481352031231,\n",
       " -0.012146682478487492,\n",
       " 0.006003967486321926,\n",
       " 0.0172046460211277,\n",
       " -0.01236111018806696,\n",
       " -0.008078868500888348,\n",
       " -0.011276359669864178,\n",
       " 0.010071782395243645,\n",
       " 0.005925134290009737,\n",
       " -0.0172046460211277,\n",
       " -0.018756091594696045,\n",
       " -0.010267289355397224,\n",
       " 0.0016089939745143056,\n",
       " -0.008930271491408348,\n",
       " 0.010361889377236366,\n",
       " -0.016094669699668884,\n",
       " -0.0373355969786644,\n",
       " 0.03178571164608002,\n",
       " -0.007618479896336794,\n",
       " -0.00440206890925765,\n",
       " 0.005338612012565136,\n",
       " -0.0269421748816967,\n",
       " -0.0422043614089489,\n",
       " -0.03385430574417114,\n",
       " 0.009573553688824177,\n",
       " 0.014707198366522789,\n",
       " -0.01016007550060749,\n",
       " 0.0029278802685439587,\n",
       " -0.004231788218021393,\n",
       " -0.027799883857369423,\n",
       " -0.025378115475177765,\n",
       " 0.009327592328190804,\n",
       " -0.0004458040639292449,\n",
       " -0.02636195905506611,\n",
       " 0.011761974543333054,\n",
       " -0.005272391717880964,\n",
       " -0.014026075601577759,\n",
       " 0.0007745402399450541,\n",
       " -0.004938137251883745,\n",
       " 0.020496739074587822,\n",
       " -0.015817174687981606,\n",
       " -0.010513249784708023,\n",
       " 0.005291312001645565,\n",
       " -0.015627974644303322,\n",
       " 0.005931440740823746,\n",
       " -0.01775963604450226,\n",
       " -0.021076953038573265,\n",
       " 0.02019401825964451,\n",
       " 0.014026075601577759,\n",
       " -0.0046764095313847065,\n",
       " 0.0030303639359772205,\n",
       " 0.029691889882087708,\n",
       " -0.010790744796395302,\n",
       " 0.006729236803948879,\n",
       " 0.015211733058094978,\n",
       " 0.0044903624802827835,\n",
       " -0.018705638125538826,\n",
       " 0.0014986268943175673,\n",
       " 0.004654336255043745,\n",
       " -0.01585501618683338,\n",
       " 0.006483275908976793,\n",
       " -0.004998050630092621,\n",
       " 0.01044387649744749,\n",
       " 0.014984692446887493,\n",
       " 0.03985827416181564,\n",
       " 0.0015766721917316318,\n",
       " 0.026866493746638298,\n",
       " -0.02235090546309948,\n",
       " 0.0020480970852077007,\n",
       " -0.016712725162506104,\n",
       " -0.005398525390774012,\n",
       " -0.020231857895851135,\n",
       " 0.014278342947363853,\n",
       " 0.022590558975934982,\n",
       " 0.006905824411660433,\n",
       " -0.012398949824273586,\n",
       " -0.0015380437253043056,\n",
       " 0.027421481907367706,\n",
       " 0.008835670538246632,\n",
       " 0.0324668325483799,\n",
       " -8.69633222464472e-05,\n",
       " -0.009586166590452194,\n",
       " -0.02189682424068451,\n",
       " 0.005546732805669308,\n",
       " 0.0011218022555112839,\n",
       " 0.008186082355678082,\n",
       " -0.008558176457881927,\n",
       " -0.007895974442362785,\n",
       " 0.022136477753520012,\n",
       " 0.036578793078660965,\n",
       " 0.00016338266141247004,\n",
       " 0.03985827416181564,\n",
       " -0.0009460033033974469,\n",
       " -0.024633925408124924,\n",
       " -0.03271910175681114,\n",
       " 0.010052861645817757,\n",
       " 0.011030398309230804,\n",
       " 0.009945647791028023,\n",
       " -0.010248369537293911,\n",
       " 0.00210801069624722,\n",
       " 0.0087662972509861,\n",
       " -0.024015869945287704,\n",
       " 0.027648523449897766,\n",
       " 0.003638959489762783,\n",
       " -0.008305909112095833,\n",
       " 0.006407595705240965,\n",
       " 0.0252393689006567,\n",
       " -0.021467968821525574,\n",
       " 0.009018564596772194,\n",
       " 0.03637697920203209,\n",
       " 0.007858133874833584,\n",
       " -0.010431263595819473,\n",
       " -0.001721726031973958,\n",
       " 0.03673015534877777,\n",
       " -0.003957447130233049,\n",
       " 0.0004619649553205818,\n",
       " -0.008450962603092194,\n",
       " 0.0031754178926348686,\n",
       " 0.0010051284916698933,\n",
       " -0.03809240087866783,\n",
       " -0.006379215512424707,\n",
       " -0.015009919181466103,\n",
       " 0.027976471930742264,\n",
       " 0.03264342248439789,\n",
       " 0.019260628148913383,\n",
       " 0.0020622871816158295,\n",
       " -0.000930236594285816,\n",
       " -0.011377266608178616,\n",
       " 0.010393423028290272,\n",
       " -0.0186677984893322,\n",
       " 0.007019344717264175,\n",
       " -0.015451387502253056,\n",
       " 0.0024343817494809628,\n",
       " -0.01748214103281498,\n",
       " -0.008419429883360863,\n",
       " -0.0030823941342532635,\n",
       " 0.012827805243432522,\n",
       " -0.0176082756370306,\n",
       " 0.009598780423402786,\n",
       " -0.007605866529047489,\n",
       " -0.004534509032964706,\n",
       " -0.004547122400254011,\n",
       " -0.0067733838222920895,\n",
       " -0.0030335173942148685,\n",
       " -0.016964992508292198,\n",
       " -0.017229873687028885,\n",
       " 0.0019219634123146534,\n",
       " 0.015035145916044712,\n",
       " -0.002932610223069787,\n",
       " -0.023574402555823326,\n",
       " -0.031432535499334335,\n",
       " -0.0020339072216302156,\n",
       " 0.008205002173781395,\n",
       " -0.0024864119477570057,\n",
       " -0.023624856024980545,\n",
       " 0.008343749679625034,\n",
       " 0.025882650166749954,\n",
       " -0.02342304214835167,\n",
       " 0.005975587759166956,\n",
       " 0.005193558055907488,\n",
       " 0.02100127376616001,\n",
       " -0.0008151395013555884,\n",
       " -0.0044872090220451355,\n",
       " -0.011024092324078083,\n",
       " 0.02585742436349392,\n",
       " 0.009087938815355301,\n",
       " 0.0027260661590844393,\n",
       " -0.020610257983207703,\n",
       " 0.0166370440274477,\n",
       " 0.0031722644343972206,\n",
       " -0.013546767644584179,\n",
       " -0.021934663876891136,\n",
       " -0.0036074260715395212,\n",
       " -0.0015750954626128078,\n",
       " -0.002316131489351392,\n",
       " 0.0012305926065891981,\n",
       " -0.004903450608253479,\n",
       " 0.002322438172996044,\n",
       " 0.018150649964809418,\n",
       " -0.0029199968557804823,\n",
       " -0.0018415531376376748,\n",
       " 0.012096229009330273,\n",
       " 0.02483574114739895,\n",
       " -0.0055025857873260975,\n",
       " -0.010973638854920864,\n",
       " -0.006697703618556261,\n",
       " -0.02603401057422161,\n",
       " -0.013017005287110806,\n",
       " 0.07330895215272903,\n",
       " 0.004039434250444174,\n",
       " -0.003563279053196311,\n",
       " 0.01463151816278696,\n",
       " -0.008696923963725567,\n",
       " -0.0034907523076981306,\n",
       " -0.04510543867945671,\n",
       " -0.027572842314839363,\n",
       " -0.006183708552271128,\n",
       " 0.0013953548623248935,\n",
       " -0.0003389845078345388,\n",
       " -0.007145478390157223,\n",
       " 1.1942060154979117e-05,\n",
       " 0.020837299525737762,\n",
       " 0.026462865993380547,\n",
       " 0.0007469484698958695,\n",
       " 0.0012660677311941981,\n",
       " -0.02460869960486889,\n",
       " -0.013571994379162788,\n",
       " 0.0011218022555112839,\n",
       " 0.004717403091490269,\n",
       " 0.005666560027748346,\n",
       " -0.00452504912391305,\n",
       " 0.016737952828407288,\n",
       " 0.021203087642788887,\n",
       " 0.0033456983510404825,\n",
       " 0.0054552857764065266,\n",
       " 0.01827678456902504,\n",
       " -0.0013606681022793055,\n",
       " 0.00016545203106943518,\n",
       " 0.014467543922364712,\n",
       " -0.006272002123296261,\n",
       " 0.01657397858798504,\n",
       " 0.007725693751126528,\n",
       " 0.017923610284924507,\n",
       " 0.014215276576578617,\n",
       " 0.008312216028571129,\n",
       " 0.03090277500450611,\n",
       " 0.009485259652137756,\n",
       " -0.005436365492641926,\n",
       " 0.017557822167873383,\n",
       " 0.007694160100072622,\n",
       " -0.003370925085619092,\n",
       " -0.022325677797198296,\n",
       " 0.017166806384921074,\n",
       " 0.01117545273154974,\n",
       " -0.009970874525606632,\n",
       " 0.013042232021689415,\n",
       " 0.0029184201266616583,\n",
       " -0.03304705023765564,\n",
       " 0.02428075112402439,\n",
       " -0.0057044001296162605,\n",
       " -0.011415106244385242,\n",
       " -0.022678852081298828,\n",
       " -0.012127762660384178,\n",
       " 0.014341410249471664,\n",
       " -0.004714249633252621,\n",
       " -0.014303569681942463,\n",
       " -0.01029882300645113,\n",
       " -0.011616921052336693,\n",
       " -0.004061507526785135,\n",
       " -0.010393423028290272,\n",
       " -0.01585501618683338,\n",
       " -0.004610189702361822,\n",
       " -0.025050166994333267,\n",
       " -0.026740361005067825,\n",
       " -0.02489880658686161,\n",
       " 0.010853811167180538,\n",
       " -0.014946852810680866,\n",
       " -0.003951140679419041,\n",
       " -0.013912555761635303,\n",
       " -0.038950107991695404,\n",
       " -0.010349276475608349,\n",
       " 0.009264525957405567,\n",
       " 0.019815616309642792,\n",
       " 0.0017784861847758293,\n",
       " -0.006836450658738613,\n",
       " -0.008097788318991661,\n",
       " 0.0002845893322955817,\n",
       " 0.013622447848320007,\n",
       " 0.0003474591358099133,\n",
       " -0.028203511610627174,\n",
       " 0.0008876664214767516,\n",
       " 0.002376045100390911,\n",
       " 0.01579194888472557,\n",
       " 0.010008715093135834,\n",
       " 0.007895974442362785,\n",
       " 0.006823837291449308,\n",
       " -0.014467543922364712,\n",
       " 0.026235824450850487,\n",
       " 0.012733204290270805,\n",
       " 0.001370916492305696,\n",
       " 0.027598069980740547,\n",
       " -0.009207765571773052,\n",
       " 0.02636195905506611,\n",
       " 0.0021679243072867393,\n",
       " 0.0071013313718140125,\n",
       " -0.007038264535367489,\n",
       " -0.013597221113741398,\n",
       " 0.006325609050691128,\n",
       " 0.0006602314533665776,\n",
       " -0.014341410249471664,\n",
       " -0.008923964574933052,\n",
       " 0.003211681265383959,\n",
       " 0.0030839708633720875,\n",
       " 0.016611818224191666,\n",
       " 0.014505384489893913,\n",
       " 0.02235090546309948,\n",
       " -0.027017854154109955,\n",
       " -0.005921980831772089,\n",
       " 0.03163434937596321,\n",
       " -0.028380099684000015,\n",
       " 0.01936153508722782,\n",
       " -0.012171909213066101,\n",
       " -0.002904230263084173,\n",
       " 0.016271257773041725,\n",
       " 0.02087513916194439,\n",
       " 0.030297333374619484,\n",
       " -0.005537272896617651,\n",
       " -0.027118761092424393,\n",
       " -0.01231065671890974,\n",
       " -0.0246717669069767,\n",
       " 0.0018573198467493057,\n",
       " 0.017633501440286636,\n",
       " 0.020345378667116165,\n",
       " -0.0038786137010902166,\n",
       " 0.006193168461322784,\n",
       " -0.019676869735121727,\n",
       " -0.006628329865634441,\n",
       " -0.01686408556997776,\n",
       " -0.01579194888472557,\n",
       " 0.02473483420908451,\n",
       " -0.001685462542809546,\n",
       " -0.01463151816278696,\n",
       " -0.028531460091471672,\n",
       " -0.013218820095062256,\n",
       " -0.007441892754286528,\n",
       " -0.0016791558591648936,\n",
       " -0.009693380445241928,\n",
       " -0.01454322412610054,\n",
       " -0.019727323204278946,\n",
       " -0.005663406569510698,\n",
       " -0.0014395017642527819,\n",
       " -0.01077813096344471,\n",
       " -0.04142233356833458,\n",
       " -0.048813771456480026,\n",
       " -0.014215276576578617,\n",
       " 0.004594422876834869,\n",
       " -0.009598780423402786,\n",
       " 0.01566581428050995,\n",
       " -0.00871584378182888,\n",
       " 0.0024643386714160442,\n",
       " -0.01566581428050995,\n",
       " -0.008608629927039146,\n",
       " -0.008343749679625034,\n",
       " -0.013294500298798084,\n",
       " 0.007435585837811232,\n",
       " -0.010450183413922787,\n",
       " 0.02817828580737114,\n",
       " 0.02590787783265114,\n",
       " 0.034661561250686646,\n",
       " 0.006565263029187918,\n",
       " 0.0007757227285765111,\n",
       " 0.014845944941043854,\n",
       " -0.0053102318197488785,\n",
       " -0.020509351044893265,\n",
       " 0.0032920914236456156,\n",
       " -0.01798667572438717,\n",
       " -0.014946852810680866,\n",
       " 0.009794287383556366,\n",
       " 0.018642572686076164,\n",
       " 0.03054960072040558,\n",
       " 0.0027528696227818727,\n",
       " 0.020105723291635513,\n",
       " 0.0009034331887960434,\n",
       " 0.0004891625721938908,\n",
       " -0.015804562717676163,\n",
       " -0.0008774180896580219,\n",
       " -0.016788406297564507,\n",
       " -0.014417090453207493,\n",
       " -0.016611818224191666,\n",
       " 0.004638569429516792,\n",
       " 0.0029483770485967398,\n",
       " 0.011206986382603645,\n",
       " 0.018314624205231667,\n",
       " -7.082707270456012e-06,\n",
       " 0.022199545055627823,\n",
       " 0.01408914290368557,\n",
       " 0.02043367177248001,\n",
       " 0.003727253060787916,\n",
       " 0.036023806780576706,\n",
       " -0.020130950957536697,\n",
       " 0.026210598647594452,\n",
       " 0.003474985482171178,\n",
       " 0.007385132368654013,\n",
       " -0.009668153710663319,\n",
       " 0.006174248177558184,\n",
       " -0.001355149783194065,\n",
       " 0.01029882300645113,\n",
       " 0.017128966748714447,\n",
       " 0.015123439952731133,\n",
       " 0.024179844185709953,\n",
       " -0.0177722480148077,\n",
       " -0.015148666687309742,\n",
       " -0.0034466052893549204,\n",
       " 0.02999461255967617,\n",
       " 0.006691396702080965,\n",
       " 0.007858133874833584,\n",
       " 0.006265695206820965,\n",
       " -0.013836875557899475,\n",
       " 0.004086734261363745,\n",
       " -0.015527067705988884,\n",
       " 0.0073472922667860985,\n",
       " -0.013319727033376694,\n",
       " 0.0085203368216753,\n",
       " -0.005130491219460964,\n",
       " -0.02626105211675167,\n",
       " 0.028985541313886642,\n",
       " -0.009554633870720863,\n",
       " -0.024924034252762794,\n",
       " -0.00478362338617444,\n",
       " 0.0009018565178848803,\n",
       " 0.042456626892089844,\n",
       " 0.0020417904015630484,\n",
       " 0.010052861645817757,\n",
       " 0.01941198855638504,\n",
       " 0.005158871412277222,\n",
       " -0.007221158593893051,\n",
       " 0.02201034314930439,\n",
       " -0.02557992935180664,\n",
       " -0.004282241687178612,\n",
       " 0.03367771953344345,\n",
       " 0.000632639741525054,\n",
       " 0.0037524797953665257,\n",
       " -0.01912187971174717,\n",
       " 0.006117488257586956,\n",
       " 0.0027844030410051346,\n",
       " -0.01613250933587551,\n",
       " -0.028607139363884926,\n",
       " 0.016838859766721725,\n",
       " 0.021631943061947823,\n",
       " -0.0033267783001065254,\n",
       " -0.020698552951216698,\n",
       " 0.013963009230792522,\n",
       " -0.03367771953344345,\n",
       " 0.015590135008096695,\n",
       " 0.0004233364888932556,\n",
       " -0.013080072589218616,\n",
       " -0.02230045199394226,\n",
       " 0.005013817455619574,\n",
       " -0.01295393891632557,\n",
       " 0.010500636883080006,\n",
       " -0.028531460091471672,\n",
       " 0.02274191938340664,\n",
       " 0.02426813915371895,\n",
       " -0.005994507577270269,\n",
       " -0.011143919080495834,\n",
       " -0.004723710007965565,\n",
       " 0.004496668931096792,\n",
       " 0.0009909385116770864,\n",
       " -0.013420633971691132,\n",
       " 0.02568083629012108,\n",
       " -0.006672476883977652,\n",
       " 0.015564908273518085,\n",
       " 0.0087662972509861,\n",
       " 0.004846690222620964,\n",
       " -0.028657592833042145,\n",
       " -0.00263934931717813,\n",
       " -0.0014670934760943055,\n",
       " 0.017797475680708885,\n",
       " -0.021240927278995514,\n",
       " 0.0015735188499093056,\n",
       " -0.008179775439202785,\n",
       " 0.01143402699381113,\n",
       " 0.00698781106621027,\n",
       " 0.01749475486576557,\n",
       " -0.008488803170621395,\n",
       " -0.0061332546174526215,\n",
       " -0.004209714941680431,\n",
       " -0.0009641350479796529,\n",
       " 0.021531036123633385,\n",
       " -0.01395039539784193,\n",
       " -0.006044961046427488,\n",
       " -0.01567842811346054,\n",
       " -0.013130526058375835,\n",
       " -0.029490076005458832,\n",
       " -0.03592289984226227,\n",
       " 0.004307468421757221,\n",
       " 0.0033173183910548687,\n",
       " -0.03196229785680771,\n",
       " -0.008438349701464176,\n",
       " -0.00829329527914524,\n",
       " -0.003088700817897916,\n",
       " 0.022552719339728355,\n",
       " 0.007971654646098614,\n",
       " -0.010286209173500538,\n",
       " 0.005231398157775402,\n",
       " 0.02251487970352173,\n",
       " -0.023574402555823326,\n",
       " -0.00456919614225626,\n",
       " 0.011301586404442787,\n",
       " 0.016674885526299477,\n",
       " -0.021064341068267822,\n",
       " 0.023952804505825043,\n",
       " -0.0030082904268056154,\n",
       " -0.015766721218824387,\n",
       " 0.004449368920177221,\n",
       " -0.01685147173702717,\n",
       " -0.006448589265346527,\n",
       " 0.010639384388923645,\n",
       " 0.009724914096295834,\n",
       " 0.00551835261285305,\n",
       " 0.003282631514593959,\n",
       " 0.0038943802937865257,\n",
       " 0.027345802634954453,\n",
       " 0.02590787783265114,\n",
       " 0.008425735868513584,\n",
       " -0.010563703253865242,\n",
       " -0.001985030248761177,\n",
       " 0.030373012647032738,\n",
       " -0.007448199205100536,\n",
       " 0.00249744881875813,\n",
       " -0.005925134290009737,\n",
       " -0.006628329865634441,\n",
       " 0.0087662972509861,\n",
       " -0.009699687361717224,\n",
       " -0.003705179551616311,\n",
       " 0.0003050860541407019,\n",
       " -0.03592289984226227,\n",
       " -0.009781674481928349,\n",
       " -0.0034308386966586113,\n",
       " 0.009523100219666958,\n",
       " 0.0057580070570111275,\n",
       " -0.01595592312514782,\n",
       " -0.030246879905462265,\n",
       " -0.01902097277343273,\n",
       " -0.0350651890039444,\n",
       " 0.0029625671450048685,\n",
       " 0.002965720370411873,\n",
       " -0.021480582654476166,\n",
       " 0.01635955087840557,\n",
       " 0.004212867934256792,\n",
       " 0.010670917108654976,\n",
       " 0.0016097823390737176,\n",
       " 0.006265695206820965,\n",
       " -0.01511082611978054,\n",
       " -0.024520406499505043,\n",
       " -0.008526642806828022,\n",
       " -0.017292940989136696,\n",
       " -0.011358346790075302,\n",
       " -0.011591694317758083,\n",
       " 0.023170774802565575,\n",
       " 0.006063881330192089,\n",
       " -0.008312216028571129,\n",
       " -0.01646045781672001,\n",
       " -0.006344528868794441,\n",
       " -0.03410657122731209,\n",
       " -0.021076953038573265,\n",
       " -0.011793508194386959,\n",
       " 0.004134034272283316,\n",
       " -0.009119471535086632,\n",
       " 0.01668749935925007,\n",
       " -0.009844740852713585,\n",
       " 0.03231547400355339,\n",
       " 0.005149411503225565,\n",
       " 0.0029893703758716583,\n",
       " 0.0019361533923074603,\n",
       " -0.025731289759278297,\n",
       " 0.012121455743908882,\n",
       " -0.0037840132135897875,\n",
       " 0.026563772931694984,\n",
       " -0.005499432794749737,\n",
       " -0.026160145178437233,\n",
       " -0.006218395195901394,\n",
       " 0.008066254667937756,\n",
       " 0.013180979527533054,\n",
       " -0.0085203368216753,\n",
       " 0.012373723089694977,\n",
       " -0.013344953767955303,\n",
       " -0.005244011525064707,\n",
       " -0.009201458655297756,\n",
       " 0.0031517676543444395,\n",
       " -0.0012597610475495458,\n",
       " 0.006048114504665136,\n",
       " 0.024406885728240013,\n",
       " -0.011591694317758083,\n",
       " -0.0014182166196405888,\n",
       " -0.0016381624154746532,\n",
       " -0.006054421421140432,\n",
       " 0.005764313507825136,\n",
       " -0.00019373359100427479,\n",
       " 0.015363093465566635,\n",
       " -0.009813208132982254,\n",
       " 0.025655610486865044,\n",
       " -0.0160694420337677,\n",
       " -0.004979130811989307,\n",
       " -0.0009231415460817516,\n",
       " -0.02116524800658226,\n",
       " 0.02019401825964451,\n",
       " -0.021543648093938828,\n",
       " 0.008968111127614975,\n",
       " 0.024255525320768356,\n",
       " 0.009844740852713585,\n",
       " 0.0006641731597483158,\n",
       " -0.0023445114493370056,\n",
       " 0.0014134866651147604,\n",
       " -0.004449368920177221,\n",
       " 0.007000424433499575,\n",
       " 8.874940249370411e-06,\n",
       " -0.013218820095062256,\n",
       " 0.0053070783615112305,\n",
       " -0.00727161206305027,\n",
       " -0.01579194888472557,\n",
       " -0.03849602863192558,\n",
       " 0.0037335597444325686,\n",
       " -0.024230297654867172,\n",
       " -0.013912555761635303,\n",
       " 0.001158065744675696,\n",
       " 0.026462865993380547,\n",
       " 0.014051302336156368,\n",
       " -0.03226501867175102,\n",
       " -0.010027634911239147,\n",
       " -0.01748214103281498,\n",
       " 0.014480157755315304,\n",
       " 0.008110402151942253,\n",
       " -0.009958261623978615,\n",
       " 0.006792303640395403,\n",
       " -0.0033488518092781305,\n",
       " -0.004758396651595831,\n",
       " 0.01957596279680729,\n",
       " -0.02121570147573948,\n",
       " -0.008425735868513584,\n",
       " 0.009214072488248348,\n",
       " 0.01816326379776001,\n",
       " -0.0036294993478804827,\n",
       " 0.037991493940353394,\n",
       " 0.24015870690345764,\n",
       " -0.01963902823626995,\n",
       " -0.008205002173781395,\n",
       " 0.02285544015467167,\n",
       " 0.021430129185318947,\n",
       " 0.016952378675341606,\n",
       " 0.003162804525345564,\n",
       " 0.0028900401666760445,\n",
       " 0.003705179551616311,\n",
       " 0.009825821034610271,\n",
       " -0.006007120944559574,\n",
       " 0.00022428161173593253,\n",
       " -0.012720591388642788,\n",
       " 0.009415886364877224,\n",
       " 0.004452522378414869,\n",
       " 0.00705718481913209,\n",
       " -0.020017430186271667,\n",
       " -0.025151073932647705,\n",
       " -0.027698976919054985,\n",
       " -0.025731289759278297,\n",
       " 0.008936578407883644,\n",
       " -0.02835487201809883,\n",
       " -0.022994186729192734,\n",
       " -0.017166806384921074,\n",
       " 0.016447843983769417,\n",
       " -0.012367417104542255,\n",
       " -0.012512470595538616,\n",
       " -0.006741850171238184,\n",
       " 0.030978454276919365,\n",
       " 0.011692601256072521,\n",
       " 0.00421602139249444,\n",
       " -0.018415531143546104,\n",
       " 0.014782878570258617,\n",
       " 0.0017784861847758293,\n",
       " -0.023675309494137764,\n",
       " -0.013609834015369415,\n",
       " 0.026008784770965576,\n",
       " 0.005915673915296793,\n",
       " 0.026891721412539482,\n",
       " 0.012411563657224178,\n",
       " -0.013168365694582462,\n",
       " -0.006193168461322784,\n",
       " -0.012241282500326633,\n",
       " -0.014480157755315304,\n",
       " 0.003478138940408826,\n",
       " 0.011774587444961071,\n",
       " ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.embed_query(\"Hello world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65747815",
   "metadata": {},
   "source": [
    "#### Python Code Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "476eb2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, PythonLoader\n",
    "\n",
    "source_code_loader = DirectoryLoader(\n",
    "    \"../vanna\", glob=\"**/*.py\", loader_cls=PythonLoader\n",
    ")\n",
    "source_code_docs = source_code_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b18d944d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(source_code_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2f5ec97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': '../vanna/tests/test_imports.py'}, page_content='def test_regular_imports():\\n    from vanna.anthropic.anthropic_chat import Anthropic_Chat\\n    from vanna.azuresearch.azuresearch_vector import AzureAISearch_VectorStore\\n    from vanna.base.base import VannaBase\\n    from vanna.bedrock.bedrock_converse import Bedrock_Converse\\n    from vanna.chromadb.chromadb_vector import ChromaDB_VectorStore\\n    from vanna.cohere.cohere_chat import Cohere_Chat\\n    from vanna.cohere.cohere_embeddings import Cohere_Embeddings\\n    from vanna.faiss.faiss import FAISS\\n    from vanna.google.bigquery_vector import BigQuery_VectorStore\\n    from vanna.google.gemini_chat import GoogleGeminiChat\\n    from vanna.hf.hf import Hf\\n    from vanna.local import LocalContext_OpenAI\\n    from vanna.marqo.marqo import Marqo_VectorStore\\n    from vanna.milvus.milvus_vector import Milvus_VectorStore\\n    from vanna.mistral.mistral import Mistral\\n    from vanna.ollama.ollama import Ollama\\n    from vanna.openai.openai_chat import OpenAI_Chat\\n    from vanna.openai.openai_embeddings import OpenAI_Embeddings\\n    from vanna.opensearch.opensearch_vector import OpenSearch_VectorStore\\n    from vanna.opensearch.opensearch_vector_semantic import (\\n      OpenSearch_Semantic_VectorStore,\\n    )\\n    from vanna.pgvector.pgvector import PG_VectorStore\\n    from vanna.pinecone.pinecone_vector import PineconeDB_VectorStore\\n    from vanna.qdrant.qdrant import Qdrant_VectorStore\\n    from vanna.qianfan.Qianfan_Chat import Qianfan_Chat\\n    from vanna.qianfan.Qianfan_embeddings import Qianfan_Embeddings\\n    from vanna.qianwen.QianwenAI_chat import QianWenAI_Chat\\n    from vanna.qianwen.QianwenAI_embeddings import QianWenAI_Embeddings\\n    from vanna.remote import VannaDefault\\n    from vanna.vannadb.vannadb_vector import VannaDB_VectorStore\\n    from vanna.weaviate.weaviate_vector import WeaviateDatabase\\n    from vanna.xinference.xinference import Xinference\\n    from vanna.ZhipuAI.ZhipuAI_Chat import ZhipuAI_Chat\\n    from vanna.ZhipuAI.ZhipuAI_embeddings import ZhipuAI_Embeddings\\n\\ndef test_shortcut_imports():\\n    from vanna.anthropic import Anthropic_Chat\\n    from vanna.azuresearch import AzureAISearch_VectorStore\\n    from vanna.base import VannaBase\\n    from vanna.chromadb import ChromaDB_VectorStore\\n    from vanna.cohere import Cohere_Chat, Cohere_Embeddings\\n    from vanna.faiss import FAISS\\n    from vanna.hf import Hf\\n    from vanna.marqo import Marqo_VectorStore\\n    from vanna.milvus import Milvus_VectorStore\\n    from vanna.mistral import Mistral\\n    from vanna.ollama import Ollama\\n    from vanna.openai import OpenAI_Chat, OpenAI_Embeddings\\n    from vanna.opensearch import (\\n      OpenSearch_Semantic_VectorStore,\\n      OpenSearch_VectorStore,\\n    )\\n    from vanna.pgvector import PG_VectorStore\\n    from vanna.pinecone import PineconeDB_VectorStore\\n    from vanna.qdrant import Qdrant_VectorStore\\n    from vanna.qianfan import Qianfan_Chat, Qianfan_Embeddings\\n    from vanna.qianwen import QianWenAI_Chat, QianWenAI_Embeddings\\n    from vanna.vannadb import VannaDB_VectorStore\\n    from vanna.vllm import Vllm\\n    from vanna.weaviate import WeaviateDatabase\\n    from vanna.xinference import Xinference\\n    from vanna.ZhipuAI import ZhipuAI_Chat, ZhipuAI_Embeddings\\n')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_code_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "549736ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import (\n",
    "    Language, RecursiveCharacterTextSplitter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1067d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON,\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1d8d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21478"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_docs = python_splitter.split_documents(source_code_docs)\n",
    "len(python_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4734b7d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': '../vanna/tests/test_imports.py'}, page_content='Anthropic_Chat')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_docs[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1f30d3",
   "metadata": {},
   "source": [
    "#### JSON Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7eccd1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error loading file ../vanna/training_data/snowflake-cost/questions.json\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "JSONLoader.__init__() missing 1 required positional argument: 'jq_schema'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_community\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdocument_loaders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DirectoryLoader, JSONLoader\n\u001b[32m      3\u001b[39m json_doc_loader = DirectoryLoader(\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m../vanna\u001b[39m\u001b[33m\"\u001b[39m, glob=\u001b[33m\"\u001b[39m\u001b[33m**/*.json\u001b[39m\u001b[33m\"\u001b[39m, loader_cls=JSONLoader\n\u001b[32m      5\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m json_docs = \u001b[43mjson_doc_loader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_community/document_loaders/directory.py:117\u001b[39m, in \u001b[36mDirectoryLoader.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> List[Document]:\n\u001b[32m    116\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load documents.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_community/document_loaders/directory.py:195\u001b[39m, in \u001b[36mDirectoryLoader.lazy_load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    194\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m items:\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lazy_load_file(i, p, pbar)\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pbar:\n\u001b[32m    198\u001b[39m     pbar.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_community/document_loaders/directory.py:233\u001b[39m, in \u001b[36mDirectoryLoader._lazy_load_file\u001b[39m\u001b[34m(self, item, path, pbar)\u001b[39m\n\u001b[32m    231\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    232\u001b[39m         logger.error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError loading file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(item)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m pbar:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langchain_community/document_loaders/directory.py:221\u001b[39m, in \u001b[36mDirectoryLoader._lazy_load_file\u001b[39m\u001b[34m(self, item, path, pbar)\u001b[39m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    220\u001b[39m     logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcessing file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(item)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m     loader = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloader_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloader_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    222\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    223\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m subdoc \u001b[38;5;129;01min\u001b[39;00m loader.lazy_load():\n",
      "\u001b[31mTypeError\u001b[39m: JSONLoader.__init__() missing 1 required positional argument: 'jq_schema'"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, JSONLoader\n",
    "\n",
    "json_doc_loader = DirectoryLoader(\n",
    "    \"../vanna\", glob=\"**/*.json\", loader_cls=JSONLoader\n",
    ")\n",
    "json_docs = json_doc_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f9cfbac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '../vanna/training_data/snowflake-cost/questions.json'}, page_content=''),\n",
       " Document(metadata={'source': '../vanna/training_data/cybersyn-financial-data/questions.json'}, page_content=''),\n",
       " Document(metadata={'source': '../vanna/training_data/cybersyn-data-commons/questions.json'}, page_content=''),\n",
       " Document(metadata={'source': '../vanna/training_data/sample-fraud/questions.json'}, page_content=''),\n",
       " Document(metadata={'source': '../vanna/training_data/sample-retention/questions.json'}, page_content=''),\n",
       " Document(metadata={'source': '../vanna/training_data/cybersyn-us-global-public/questions.json'}, page_content=''),\n",
       " Document(metadata={'source': '../vanna/training_data/sample-imdb/questions.json'}, page_content=''),\n",
       " Document(metadata={'source': '../vanna/training_data/tpc-h/questions.json'}, page_content=''),\n",
       " Document(metadata={'source': '../vanna/training_data/fivetran-ads-snowflake/questions.json'}, page_content=''),\n",
       " Document(metadata={'source': '../vanna/training_data/sample-salaries/questions.json'}, page_content=''),\n",
       " Document(metadata={'source': '../vanna/training_data/similarweb/questions.json'}, page_content='')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e832c57",
   "metadata": {},
   "source": [
    "#### GithubFileLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fda12de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import GithubFileLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e320a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = GithubFileLoader(\n",
    "    repo=\"vanna-ai/vanna\",\n",
    "    branch=\"main\",\n",
    "    access_token=os.getenv('GITHUB_ACCESS_TOKEN'),\n",
    "    github_api_url=\"https://api.github.com\",\n",
    "    file_filter=lambda file_path: file_path.endswith(\".md\"),\n",
    ")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a103a9b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'path': '.github/ISSUE_TEMPLATE/bug_report.md', 'sha': '977810a19a617b270c84db3815b90542fd21903f', 'source': 'https://api.github.com/vanna-ai/vanna/blob/main/.github/ISSUE_TEMPLATE/bug_report.md'}, page_content='---\\r\\nname: Bug report\\r\\nabout: Create a report to help us improve\\r\\ntitle: \\'\\'\\r\\nlabels: [\"bug\"]\\r\\nassignees: \\'\\'\\r\\n\\r\\n---\\r\\n\\r\\n**Describe the bug**\\r\\nA clear and concise description of what the bug is.\\r\\n\\r\\n**To Reproduce**\\r\\nSteps to reproduce the behavior:\\r\\n1. Go to \\'...\\'\\r\\n2. Click on \\'....\\'\\r\\n3. Scroll down to \\'....\\'\\r\\n4. See error\\r\\n\\r\\n**Expected behavior**\\r\\nA clear and concise description of what you expected to happen.\\r\\n\\r\\n**Error logs/Screenshots**\\r\\nIf applicable, add logs/screenshots to give more information about the issue.\\r\\n\\r\\n**Desktop (please complete the following information where):**\\r\\n - OS: [e.g. Ubuntu]\\r\\n - Version: [e.g. 20.04]\\r\\n - Python: [3.9]\\r\\n - Vanna: [2.8.0]\\r\\n\\r\\n**Additional context**\\r\\nAdd any other context about the problem here.\\r\\n'),\n",
       " Document(metadata={'path': '.github/ISSUE_TEMPLATE/feature_request.md', 'sha': '7485b1fe9824cbc387cc2c0032973e2a41c646f5', 'source': 'https://api.github.com/vanna-ai/vanna/blob/main/.github/ISSUE_TEMPLATE/feature_request.md'}, page_content='---\\r\\nname: Feature request\\r\\nabout: Suggest an idea for this project\\r\\ntitle: \\'\\'\\r\\nlabels: [\"enhancements\"]\\r\\nassignees: \\'\\'\\r\\n\\r\\n---\\r\\n\\r\\n**Is your feature request related to a problem? Please describe.**\\r\\nA clear and concise description of what the problem is. Ex. I\\'m always frustrated when [...]\\r\\n\\r\\n**Describe the solution you\\'d like**\\r\\nA clear and concise description of what you want to happen.\\r\\n\\r\\n**Describe alternatives you\\'ve considered**\\r\\nA clear and concise description of any alternative solutions or features you\\'ve considered.\\r\\n\\r\\n**Additional context**\\r\\nAdd any other context or screenshots about the feature request here.\\r\\n'),\n",
       " Document(metadata={'path': 'CONTRIBUTING.md', 'sha': '15ff1bcdea708fbfba57c8d660d0dfa286d1e1b2', 'source': 'https://api.github.com/vanna-ai/vanna/blob/main/CONTRIBUTING.md'}, page_content=\"# Contributing\\n\\n## Setup\\n```bash\\ngit clone https://github.com/vanna-ai/vanna.git\\ncd vanna/\\n\\npython3 -m venv venv\\nsource venv/bin/activate\\n\\n# install package in editable mode\\npip install -e '.[all]' tox pre-commit\\n\\n# Setup pre-commit hooks\\npre-commit install\\n\\n# List dev targets\\ntox list\\n\\n# Run tests\\ntox -e py310\\n```\\n\\n## Running the test on a Mac\\n```bash\\ntox -e mac\\n```\\n\\n## Do this before you submit a PR:\\n\\nFind the most relevant sample notebook and then replace the install command with:\\n\\n```bash\\n%pip install 'git+https://github.com/vanna-ai/vanna@your-branch#egg=vanna[chromadb,snowflake,openai]'\\n```\\n\\nRun the necessary cells and verify that it works as expected in a real-world scenario.\\n\"),\n",
       " Document(metadata={'path': 'README.md', 'sha': 'dd252217715486451a6a90d5cce2af2cb83c5918', 'source': 'https://api.github.com/vanna-ai/vanna/blob/main/README.md'}, page_content='\\n\\n| GitHub | PyPI | Documentation | Gurubase |\\n| ------ | ---- | ------------- | -------- |\\n| [![GitHub](https://img.shields.io/badge/GitHub-vanna-blue?logo=github)](https://github.com/vanna-ai/vanna) | [![PyPI](https://img.shields.io/pypi/v/vanna?logo=pypi)](https://pypi.org/project/vanna/) | [![Documentation](https://img.shields.io/badge/Documentation-vanna-blue?logo=read-the-docs)](https://vanna.ai/docs/) | [![Gurubase](https://img.shields.io/badge/Gurubase-Ask%20Vanna%20Guru-006BFF)](https://gurubase.io/g/vanna) |\\n\\n# Vanna\\nVanna is an MIT-licensed open-source Python RAG (Retrieval-Augmented Generation) framework for SQL generation and related functionality.\\n\\nhttps://github.com/vanna-ai/vanna/assets/7146154/1901f47a-515d-4982-af50-f12761a3b2ce\\n\\n![vanna-quadrants](https://github.com/vanna-ai/vanna/assets/7146154/1c7c88ba-c144-4ecf-a028-cf5ba7344ca2)\\n\\n## How Vanna works\\n\\n![Screen Recording 2024-01-24 at 11 21 37\\u202fAM](https://github.com/vanna-ai/vanna/assets/7146154/1d2718ad-12a8-4a76-afa2-c61754462f93)\\n\\n\\nVanna works in two easy steps - train a RAG \"model\" on your data, and then ask questions which will return SQL queries that can be set up to automatically run on your database.\\n\\n1. **Train a RAG \"model\" on your data**.\\n2. **Ask questions**.\\n\\n![](img/vanna-readme-diagram.png)\\n\\nIf you don\\'t know what RAG is, don\\'t worry -- you don\\'t need to know how this works under the hood to use it. You just need to know that you \"train\" a model, which stores some metadata and then use it to \"ask\" questions.\\n\\nSee the [base class](https://github.com/vanna-ai/vanna/blob/main/src/vanna/base/base.py) for more details on how this works under the hood.\\n\\n## User Interfaces\\nThese are some of the user interfaces that we\\'ve built using Vanna. You can use these as-is or as a starting point for your own custom interface.\\n\\n- [Jupyter Notebook](https://vanna.ai/docs/postgres-openai-vanna-vannadb/)\\n- [vanna-ai/vanna-streamlit](https://github.com/vanna-ai/vanna-streamlit)\\n- [vanna-ai/vanna-flask](https://github.com/vanna-ai/vanna-flask)\\n- [vanna-ai/vanna-slack](https://github.com/vanna-ai/vanna-slack)\\n\\n## Supported LLMs\\n\\n- [OpenAI](https://github.com/vanna-ai/vanna/tree/main/src/vanna/openai)\\n- [Anthropic](https://github.com/vanna-ai/vanna/tree/main/src/vanna/anthropic)\\n- [Gemini](https://github.com/vanna-ai/vanna/blob/main/src/vanna/google/gemini_chat.py)\\n- [HuggingFace](https://github.com/vanna-ai/vanna/blob/main/src/vanna/hf/hf.py)\\n- [AWS Bedrock](https://github.com/vanna-ai/vanna/tree/main/src/vanna/bedrock)\\n- [Ollama](https://github.com/vanna-ai/vanna/tree/main/src/vanna/ollama)\\n- [Qianwen](https://github.com/vanna-ai/vanna/tree/main/src/vanna/qianwen)\\n- [Qianfan](https://github.com/vanna-ai/vanna/tree/main/src/vanna/qianfan)\\n- [Zhipu](https://github.com/vanna-ai/vanna/tree/main/src/vanna/ZhipuAI)\\n\\n## Supported VectorStores\\n\\n- [AzureSearch](https://github.com/vanna-ai/vanna/tree/main/src/vanna/azuresearch)\\n- [Opensearch](https://github.com/vanna-ai/vanna/tree/main/src/vanna/opensearch)\\n- [PgVector](https://github.com/vanna-ai/vanna/tree/main/src/vanna/pgvector)\\n- [PineCone](https://github.com/vanna-ai/vanna/tree/main/src/vanna/pinecone)\\n- [ChromaDB](https://github.com/vanna-ai/vanna/tree/main/src/vanna/chromadb)\\n- [FAISS](https://github.com/vanna-ai/vanna/tree/main/src/vanna/faiss)\\n- [Marqo](https://github.com/vanna-ai/vanna/tree/main/src/vanna/marqo)\\n- [Milvus](https://github.com/vanna-ai/vanna/tree/main/src/vanna/milvus)\\n- [Qdrant](https://github.com/vanna-ai/vanna/tree/main/src/vanna/qdrant)\\n- [Weaviate](https://github.com/vanna-ai/vanna/tree/main/src/vanna/weaviate)\\n- [Oracle](https://github.com/vanna-ai/vanna/tree/main/src/vanna/oracle)\\n\\n## Supported Databases\\n\\n- [PostgreSQL](https://www.postgresql.org/)\\n- [MySQL](https://www.mysql.com/)\\n- [PrestoDB](https://prestodb.io/)\\n- [Apache Hive](https://hive.apache.org/)\\n- [ClickHouse](https://clickhouse.com/)\\n- [Snowflake](https://www.snowflake.com/en/)\\n- [Oracle](https://www.oracle.com/)\\n- [Microsoft SQL Server](https://www.microsoft.com/en-us/sql-server/sql-server-downloads)\\n- [BigQuery](https://cloud.google.com/bigquery)\\n- [SQLite](https://www.sqlite.org/)\\n- [DuckDB](https://duckdb.org/)\\n\\n\\n## Getting started\\nSee the [documentation](https://vanna.ai/docs/) for specifics on your desired database, LLM, etc.\\n\\nIf you want to get a feel for how it works after training, you can try this [Colab notebook](https://vanna.ai/docs/app/).\\n\\n\\n### Install\\n```bash\\npip install vanna\\n```\\n\\nThere are a number of optional packages that can be installed so see the [documentation](https://vanna.ai/docs/) for more details.\\n\\n### Import\\nSee the [documentation](https://vanna.ai/docs/) if you\\'re customizing the LLM or vector database.\\n\\n```python\\n# The import statement will vary depending on your LLM and vector database. This is an example for OpenAI + ChromaDB\\n\\nfrom vanna.openai.openai_chat import OpenAI_Chat\\nfrom vanna.chromadb.chromadb_vector import ChromaDB_VectorStore\\n\\nclass MyVanna(ChromaDB_VectorStore, OpenAI_Chat):\\n    def __init__(self, config=None):\\n        ChromaDB_VectorStore.__init__(self, config=config)\\n        OpenAI_Chat.__init__(self, config=config)\\n\\nvn = MyVanna(config={\\'api_key\\': \\'sk-...\\', \\'model\\': \\'gpt-4-...\\'})\\n\\n# See the documentation for other options\\n\\n```\\n\\n\\n## Training\\nYou may or may not need to run these `vn.train` commands depending on your use case. See the [documentation](https://vanna.ai/docs/) for more details.\\n\\nThese statements are shown to give you a feel for how it works.\\n\\n### Train with DDL Statements\\nDDL statements contain information about the table names, columns, data types, and relationships in your database.\\n\\n```python\\nvn.train(ddl=\"\"\"\\n    CREATE TABLE IF NOT EXISTS my-table (\\n        id INT PRIMARY KEY,\\n        name VARCHAR(100),\\n        age INT\\n    )\\n\"\"\")\\n```\\n\\n### Train with Documentation\\nSometimes you may want to add documentation about your business terminology or definitions.\\n\\n```python\\nvn.train(documentation=\"Our business defines XYZ as ...\")\\n```\\n\\n### Train with SQL\\nYou can also add SQL queries to your training data. This is useful if you have some queries already laying around. You can just copy and paste those from your editor to begin generating new SQL.\\n\\n```python\\nvn.train(sql=\"SELECT name, age FROM my-table WHERE name = \\'John Doe\\'\")\\n```\\n\\n\\n## Asking questions\\n```python\\nvn.ask(\"What are the top 10 customers by sales?\")\\n```\\n\\nYou\\'ll get SQL\\n```sql\\nSELECT c.c_name as customer_name,\\n        sum(l.l_extendedprice * (1 - l.l_discount)) as total_sales\\nFROM   snowflake_sample_data.tpch_sf1.lineitem l join snowflake_sample_data.tpch_sf1.orders o\\n        ON l.l_orderkey = o.o_orderkey join snowflake_sample_data.tpch_sf1.customer c\\n        ON o.o_custkey = c.c_custkey\\nGROUP BY customer_name\\nORDER BY total_sales desc limit 10;\\n```\\n\\nIf you\\'ve connected to a database, you\\'ll get the table:\\n<div>\\n<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>CUSTOMER_NAME</th>\\n      <th>TOTAL_SALES</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>0</th>\\n      <td>Customer#000143500</td>\\n      <td>6757566.0218</td>\\n    </tr>\\n    <tr>\\n      <th>1</th>\\n      <td>Customer#000095257</td>\\n      <td>6294115.3340</td>\\n    </tr>\\n    <tr>\\n      <th>2</th>\\n      <td>Customer#000087115</td>\\n      <td>6184649.5176</td>\\n    </tr>\\n    <tr>\\n      <th>3</th>\\n      <td>Customer#000131113</td>\\n      <td>6080943.8305</td>\\n    </tr>\\n    <tr>\\n      <th>4</th>\\n      <td>Customer#000134380</td>\\n      <td>6075141.9635</td>\\n    </tr>\\n    <tr>\\n      <th>5</th>\\n      <td>Customer#000103834</td>\\n      <td>6059770.3232</td>\\n    </tr>\\n    <tr>\\n      <th>6</th>\\n      <td>Customer#000069682</td>\\n      <td>6057779.0348</td>\\n    </tr>\\n    <tr>\\n      <th>7</th>\\n      <td>Customer#000102022</td>\\n      <td>6039653.6335</td>\\n    </tr>\\n    <tr>\\n      <th>8</th>\\n      <td>Customer#000098587</td>\\n      <td>6027021.5855</td>\\n    </tr>\\n    <tr>\\n      <th>9</th>\\n      <td>Customer#000064660</td>\\n      <td>5905659.6159</td>\\n    </tr>\\n  </tbody>\\n</table>\\n</div>\\n\\nYou\\'ll also get an automated Plotly chart:\\n![](img/top-10-customers.png)\\n\\n## RAG vs. Fine-Tuning\\nRAG\\n- Portable across LLMs\\n- Easy to remove training data if any of it becomes obsolete\\n- Much cheaper to run than fine-tuning\\n- More future-proof -- if a better LLM comes out, you can just swap it out\\n\\nFine-Tuning\\n- Good if you need to minimize tokens in the prompt\\n- Slow to get started\\n- Expensive to train and run (generally)\\n\\n## Why Vanna?\\n\\n1. **High accuracy on complex datasets.**\\n    - Vanna’s capabilities are tied to the training data you give it\\n    - More training data means better accuracy for large and complex datasets\\n2. **Secure and private.**\\n    - Your database contents are never sent to the LLM or the vector database\\n    - SQL execution happens in your local environment\\n3. **Self learning.**\\n    - If using via Jupyter, you can choose to \"auto-train\" it on the queries that were successfully executed\\n    - If using via other interfaces, you can have the interface prompt the user to provide feedback on the results\\n    - Correct question to SQL pairs are stored for future reference and make the future results more accurate\\n4. **Supports any SQL database.**\\n    - The package allows you to connect to any SQL database that you can otherwise connect to with Python\\n5. **Choose your front end.**\\n    - Most people start in a Jupyter Notebook.\\n    - Expose to your end users via Slackbot, web app, Streamlit app, or a custom front end.\\n\\n## Extending Vanna\\nVanna is designed to connect to any database, LLM, and vector database. There\\'s a [VannaBase](https://github.com/vanna-ai/vanna/blob/main/src/vanna/base/base.py) abstract base class that defines some basic functionality. The package provides implementations for use with OpenAI and ChromaDB. You can easily extend Vanna to use your own LLM or vector database. See the [documentation](https://vanna.ai/docs/) for more details.\\n\\n## Vanna in 100 Seconds\\n\\nhttps://github.com/vanna-ai/vanna/assets/7146154/eb90ee1e-aa05-4740-891a-4fc10e611cab\\n\\n## More resources\\n - [Full Documentation](https://vanna.ai/docs/)\\n - [Website](https://vanna.ai)\\n - [Discord group for support](https://discord.gg/qUZYKHremx)\\n'),\n",
       " Document(metadata={'path': 'papers/ai-sql-accuracy-2023-08-17.md', 'sha': '082b5edb15bfc8e6d75b2c26e5b04e4814426b1b', 'source': 'https://api.github.com/vanna-ai/vanna/blob/main/papers/ai-sql-accuracy-2023-08-17.md'}, page_content='# AI SQL Accuracy: Testing different LLMs + context strategies to maximize SQL generation accuracy\\n_2023-08-17_\\n\\n## TLDR\\n\\nThe promise of having an autonomous AI agent that can answer business users’ plain English questions is an attractive but thus far elusive proposition. Many have tried, with limited success, to get ChatGPT to write. The failure is primarily due of a lack of the LLM\\'s knowledge of the particular dataset it’s being asked to query.\\n\\nIn this paper, **we show that context is everything, and with the right context, we can get from ~3% accuracy to ~80% accuracy**.\\xa0We go through three different context strategies, and showcase one that is the clear winner - where we combine schema definitions, documentation, and prior SQL queries with a relevance search.\\n\\nWe also compare a few different LLMs - including Google Bison, GPT 3.5, GPT 4, and a brief attempt with Llama 2. While **GPT 4 takes the crown of the best overall LLM for generating SQL**, Google’s Bison is roughly equivalent when enough context is provided.\\n\\nFinally, we show how you can use the methods demonstrated here to generate SQL for your database.\\n\\nHere\\'s a summary of our key findings -\\n\\n![](https://raw.githubusercontent.com/vanna-ai/vanna/main/papers/img/summary.png)\\n\\n## Table of Contents\\n* [Why use AI to generate SQL?](#why-use-ai-to-generate-sql)\\n* [Setting up architecture of the test](#setting-up-architecture-of-the-test)\\n* [Setting up the test levers](#setting-up-the-test-levers)\\n    * [Choosing a dataset](#choosing-a-dataset)\\n    * [Choosing the questions](#choosing-the-questions)\\n    * [Choosing the prompt](#choosing-the-prompt)\\n    * [Choosing the LLMs (Foundational models)](#choosing-the-llms-foundational-models)\\n    * [Choosing the context](#choosing-the-context)\\n* [Using ChatGPT to generate SQL](#using-chatgpt-to-generate-sql)\\n* [Using schema only](#using-schema-only)\\n* [Using SQL examples](#using-sql-examples)\\n* [Using contextually relevant examples](#using-contextually-relevant-examples)\\n* [Analyzing the results](#analyzing-the-results)\\n* [Next steps to getting accuracy even higher](#next-steps-to-getting-accuracy-even-higher)\\n* [Use AI to write SQL for your dataset](#use-ai-to-write-sql-for-your-dataset)\\n\\n\\n\\n## Why use AI to generate SQL?\\n\\nMany organizations have now adopted some sort of data warehouse or data lake - a repository of a lot of the organization’s critical data that is queryable for analytical purposes. This ocean of data is brimming with potential insights, but only a small fraction of people in an enterprise have the two skills required to harness the data —\\n\\n1. A solid comprehension of **advanced SQL**, and\\n2. A comprehensive knowledge of the **organization’s unique data structure & schema**\\n\\nThe number of people with both of the above is not only vanishingly small, but likely not the same people that have the majority of the questions.\\xa0\\n\\n**So what actually happens inside organizations?** Business users, like product managers, sales managers, and executives, have data questions that will inform business decisions and strategy. They’ll first check dashboards, but most questions are ad hoc and specific, and the answers aren’t available, so they’ll ask a data analyst or engineer - whomever possesses the combination of skills above. These people are busy, and take a while to get to the request, and as soon as they get an answer, the business user has follow up questions.\\xa0\\n\\n**This process is painful** for both the business user (long lead times to get answers) and the analyst (distracts from their main projects), and leads to many potential insights being lost.\\n\\n![](https://raw.githubusercontent.com/vanna-ai/vanna/main/papers/img/question-flow.png)\\n\\n**Enter generative AI!** LLMs potentially give the opportunity to business users to query the database in plain English (with the LLMs doing the SQL translation), and we have heard from dozens of companies that this would be a game changer for their data teams and even their businesses.\\n\\n**The key challenge is generating accurate SQL for complex and messy databases**. Plenty of people we’ve spoken with have tried to use ChatGPT to write SQL with limited success and a lot of pain. Many have given up and reverted back to the old fashioned way of manually writing SQL. At best, ChatGPT is a sometimes useful co-pilot for analysts to get syntax right.\\n\\n**But there’s hope!** We’ve spent the last few months immersed in this problem, trying various models, techniques and approaches to improve the accuracy of SQL generated by LLMs. In this paper, we show the performance of various LLMs and how the strategy of providing contextually relevant correct SQL to the LLM can allow the LLM to **achieve extremely high accuracy**.\\n\\n\\n## Setting up architecture of the test\\n\\nFirst, we needed to define the architecture of the test. A rough outline is below, in a five step process, with _pseudo code_ below -\\xa0\\n\\n![](https://raw.githubusercontent.com/vanna-ai/vanna/main/papers/img/test-architecture.png)\\n\\n1. **Question** - We start with the business question.\\n```python\\n   question = \"how many clients are there in germany\"\\n```\\n2. **Prompt** - We create the prompt to send to the LLM.\\n```python\\n   prompt = f\"\"\"\\n   Write a SQL statement for the following question:\\n   {question}\\n   \"\"\"\\n```\\n3. **Generate SQL** - Using an API, we’ll send the prompt to the LLM and get back generated SQL.\\n```python\\n   sql = llm.api(api_key=api_key, prompt=prompt, parameters=parameters)\\n```\\n4. **Run SQL** - We\\'ll run the SQL against the database.\\n```python\\n    df = db.conn.execute(sql)\\n```\\n5. **Validate results** - Finally, we’ll validate that the results are in line with what we expect.\\nThere are some shades of grey when it comes to the results so we did a manual evaluation of the results. You can see those results [here](https://github.com/vanna-ai/research/blob/main/data/sec_evaluation_data_tagged.csv)\\n\\n## Setting up the test levers\\n\\nNow that we have our experiment set up, we’ll need to figure out what levers would impact accuracy, and what our test set would be. We tried two levers (the LLMs and the training data used), and we ran on 20 questions that made up our test set. So we ran a total of 3 LLMs x 3 context strategies x 20 questions = 180 individual trials in this experiment.\\n\\n![](https://raw.githubusercontent.com/vanna-ai/vanna/main/papers/img/test-levers.png)\\n\\n\\n### Choosing a dataset\\n\\nFirst, we need to **choose an appropriate dataset** to try. We had a few guiding principles -\\xa0\\n\\n1. **Representative**. Datasets in enterprises are often complex and this complexity isn’t captured in many demo / sample datasets. We want to use a complicated database that has real-word use cases that contains real-world data.\\xa0\\n2. **Accessible**. We also wanted that dataset to be publicly available.\\xa0\\n3. **Understandable**. The dataset should be somewhat understandable to a wide audience - anything too niche or technical would be difficult to decipher.\\n4. **Maintained**. We’d prefer a dataset that’s maintained and updated properly, in reflection of a real database.\\n\\nA dataset that we found that met the criteria above was the Cybersyn SEC filings dataset, which is available for free on the Snowflake marketplace:\\xa0\\n\\nhttps://docs.cybersyn.com/our-data-products/economic-and-financial/sec-filings\\n\\n\\n### Choosing the questions\\n\\nNext, we need to **choose the questions**. Here are some sample questions (see them all in this [file](https://github.com/vanna-ai/research/blob/main/data/questions_sec.csv)) -\\xa0\\n\\n1. How many companies are there in the dataset?\\n2. What annual measures are available from the \\'ALPHABET INC.\\' Income Statement?\\n3. What are the quarterly \\'Automotive sales\\' and \\'Automotive leasing\\' for Tesla?\\n4. How many Chipotle restaurants are there currently?\\n\\nNow that we have the dataset + questions, we’ll need to come up with the levers.\\xa0\\n\\n### Choosing the prompt\\n\\nFor the **prompt**, for this run, we are going to hold the prompt constant, though we’ll do a follow up which varies the prompt.\\n\\n### Choosing the LLMs (Foundational models)\\n\\nFor the **LLMs** to test, we’ll try the following -\\xa0\\n\\n1. [**Bison (Google)**](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models) - Bison is the version of [PaLM 2](https://blog.google/technology/ai/google-palm-2-ai-large-language-model/) that’s available via GCP APIs.\\n2. [**GPT 3.5 Turbo (OpenAI)**](https://platform.openai.com/docs/models/gpt-3-5) - GPT 3.5 until recently was the flagship OpenAI model despite 4 being available because of latency and cost benefits, and not a huge accuracy difference (well - we’ll put that to the test) especially for basic tasks.\\n3. [**GPT 4 (OpenAI)**](https://platform.openai.com/docs/models/gpt-4) - The more advanced but less performant OpenAI model. GPT 4 is multi-modal, though we won’t be using that functionality.\\n4. [**Llama 2 (Meta)**](https://ai.meta.com/llama/) - We really wanted to include an open source model - and the leading one is Meta’s Llama 2. But our setup through [Replicate](https://replicate.com/replicate/llama-2-70b-chat) quickly conked out, and we weren’t able to fix it in time for publishing this. In our early runs, when it did work, we found performance to be mediocre at best.\\n\\n\\n### Choosing the context\\n\\nFinally, we’ll have three types of **context**. Context refers to what we send to the LLM that helps give the LLM context on our specific dataset.\\n\\n1. **Schema only**. We put the schema (using DDL) in the context window.\\n2. **Static examples**. We put static example SQL queries in the context windows.\\n3. **Contextually relevant examples**. Finally, we put the most relevant context (SQL / DDL / documentation) into the context window, finding it via a vector search based on embeddings.\\n\\n\\n## Using ChatGPT to generate SQL\\n\\nThis section is a bit unfair to ChatGPT, but it’s a helpful place to get started. Let’s just take a question and ask ChatGPT to generate the SQL -\\xa0\\n\\n**Prompt**\\n\\n```\\nWrite Snowflake SQL to answer the following question -\\n\\nWhat are the quarterly revenues by business segment for Alphabet?\\n\\nReturn SQL only\\n```\\n\\n**Response**\\n\\nCertainly, here\\'s the SQL query:\\n\\n```sql\\nSELECT\\n  EXTRACT(QUARTER FROM date_column) AS quarter,\\n  business_segment,\\n  SUM(revenue) AS quarterly_revenue\\nFROM\\n  revenue_table\\nWHERE\\n  company_name = \\'Alphabet\\'\\nGROUP BY\\n  quarter,\\n  business_segment\\nORDER BY\\n  quarter,\\n  business_segment;\\n\\n-- Replace date_column, business_segment, revenue, revenue_table, and adjust any other identifiers to match your specific database schema.\\n```\\n\\nInevitably, when we try to run this, we hit an error, because it made up the table name since we didn\\'t provide it -\\xa0\\n\\n![](https://raw.githubusercontent.com/vanna-ai/vanna/main/papers/img/sql-error.png)\\n\\nOf course, we are being unfair to the LLMs - as magical as they are, they cannot (unfortunately? luckily?) possibly know what’s in our database - yet. So let’s hop into the tests where we give more context.\\n\\n\\n## Using schema only\\n\\nFirst, we take the schema of the dataset and put it into the context window. This is usually what we\\'ve seen people do with ChatGPT or in tutorials.\\n\\nAn example prompt may look like this (in reality we used the information schema because of how Snowflake shares work but this shows the principle) -\\xa0\\n\\n```\\nThe user provides a question and you provide SQL. You will only respond with SQL code and not with any explanations.\\n\\nRespond with only SQL code. Do not answer with any explanations -- just the code.\\n\\nYou may use the following DDL statements as a reference for what tables might be available.\\n\\nCREATE TABLE Table1...\\n\\nCREATE TABLE Table2...\\n\\nCREATE TABLE Table3...\\n```\\n\\nThe results were, in a word, terrible. Of the 60 attempts (20 questions x 3 models), only two questions were answered correctly (both by GPT 4), **for an abysmal accuracy rate of 3%**. Here are the two questions that GPT 4 managed to get right -\\xa0\\n\\n1. What are the top 10 measure descriptions by frequency?\\n2. What are the distinct statements in the report attributes?\\n\\n![](https://raw.githubusercontent.com/vanna-ai/vanna/main/papers/img/accuracy-using-schema-only.png)\\n\\nIt’s evident that by just using the schema, we don’t get close to meeting the bar of a helpful AI SQL agent, though it may be somewhat useful in being an analyst copilot.\\n\\n\\n## Using SQL examples\\n\\nIf we put ourselves in the shoes of a human who’s exposed to this dataset for the first time, in addition to the table definitions, they’d first look at the example queries to see _how_ to query the database correctly.\\n\\nThese queries can give additional context not available in the schema - for example, which columns to use, how tables join together, and other intricacies of querying that particular dataset.\\n\\nCybersyn, as with other data providers on the Snowflake marketplace, provides a few (in this case 3) example queries in their documentation. Let’s include these in the context window.\\n\\nBy providing just those 3 example queries, we see substantial improvements to the correctness of the SQL generated. However, this accuracy greatly varies by the underlying LLM. It seems that GPT-4 is the most able to generalize the example queries in a way that generates the most accurate SQL.\\n\\n![](https://raw.githubusercontent.com/vanna-ai/vanna/main/papers/img/accuracy-using-static-examples.png)\\n\\n## Using contextually relevant examples\\n\\nEnterprise data warehouses often contain 100s (or even 1000s) of tables, and an order of magnitude more queries that cover all the use cases within their organizations. Given the limited size of the context windows of modern LLMs, we can’t just shove all the prior queries and schema definitions into the prompt.\\n\\nOur final approach to context is a more sophisticated ML approach - load embeddings of prior queries and the table schemas into a vector database, and only choose the most relevant queries / tables to the question asked. Here\\'s a diagram of what we are doing - note the contextual relevance search in the green box -\\n\\n![](https://raw.githubusercontent.com/vanna-ai/vanna/main/papers/img/using-contextually-relevant-examples.png)\\n\\nBy surfacing the most relevant examples of those SQL queries to the LLM, we can drastically improve performance of even the less capable LLMs. Here, we give the LLM the 10 most relevant SQL query examples for the question (from a list of 30 examples stored), and accuracy rates skyrocket.\\n\\n![](https://raw.githubusercontent.com/vanna-ai/vanna/main/papers/img/accuracy-using-contextual-examples.png)\\n\\nWe can improve performance even more by maintaining a history of SQL statements that were executable and correctly answer actual questions that users have had.\\n\\n\\n## Analyzing the results\\n\\nIt’s clear that the biggest difference is not in the type of LLM, but rather in the strategy employed to give the appropriate context to the LLM (eg the “training data” used).\\n\\n![](https://raw.githubusercontent.com/vanna-ai/vanna/main/papers/img/summary-table.png)\\n\\nWhen looking at SQL accuracy by context strategy, it’s clear that this is what makes the difference. We go from ~3% accurate using just the schema, to ~80% accurate when intelligently using contextual examples.\\n\\n![](https://raw.githubusercontent.com/vanna-ai/vanna/main/papers/img/summary.png)\\n\\nThere are still interesting trends with the LLMs themselves. While Bison starts out at the bottom of the heap in both the Schema and Static context strategies, it rockets to the top with a full Contextual strategy. Averaged across the three strategies, **GPT 4 takes the crown as the best LLM for SQL generation**.\\n\\n![](https://raw.githubusercontent.com/vanna-ai/vanna/main/papers/img/accuracy-by-llm.png)\\n\\n## Next steps to getting accuracy even higher\\n\\nWe\\'ll soon do a follow up on this analysis to get even deeper into accurate SQL generation. Some next steps are -\\n\\n1. **Use other datasets**: We\\'d love to try this on other, real world, enterprise datasets. What happens when you get to 100 tables? 1000 tables?\\n2. **Add more training data**: While 30 queries is great, what happens when you 10x, 100x that number?\\n3. **Try more databases**: This test was run on a Snowflake database, but we\\'ve also gotten this working on BigQuery, Postgres, Redshift, and SQL Server.\\n4. **Experiment with more foundational models:** We are close to being able to use Llama 2, and we\\'d love to try other LLMs.\\n\\nWe have some anecdotal evidence for the above but we\\'ll be expanding and refining our tests to include more of these items.\\n\\n## Use AI to write SQL for your dataset\\n\\nWhile the SEC data is a good start, you must be wondering whether this could be relevant for your data and your organization. We’re building a [Python package](https://vanna.ai) that can generate SQL for your database as well as additional functionality like being able to generate Plotly code for the charts, follow-up questions, and various other functions.\\n\\nHere\\'s an overview of how it works\\n```python\\nimport vanna as vn\\n```\\n\\n1. **Train Using Schema**\\n\\n```python\\nvn.train(ddl=\"CREATE TABLE ...\")\\n```\\n\\n2. **Train Using Documentation**\\n\\n```python\\nvn.train(documentation=\"...\")\\n```\\n\\n3. **Train Using SQL Examples**\\n\\n```python\\nvn.train(sql=\"SELECT ...\")\\n```\\n\\n4. **Generating SQL**\\n\\nThe easiest ways to use Vanna out of the box are `vn.ask(question=\"What are the ...\")` which will return the SQL, table, and chart as you can see in this [example notebook](https://vanna.ai/docs/getting-started.html). `vn.ask` is a wrapper around `vn.generate_sql`, `vn.run_sql`, `vn.generate_plotly_code`, `vn.get_plotly_figure`, and `vn.generate_followup_questions`. This will use optimized context to generate SQL for your question where Vanna will call the LLM for you.\\n\\nAlternately, you can use `vn.get_related_training_data(question=\"What are the ...\")` as shown in this [notebook](https://github.com/vanna-ai/research/blob/main/notebooks/test-cybersyn-sec.ipynb) which will retrieve the most relevant context that you can use to construct your own prompt to send to any LLM.\\n\\nThis [notebook](https://github.com/vanna-ai/research/blob/main/notebooks/train-cybersyn-sec-3.ipynb) shows an example of how the \"Static\" context strategy was used to train Vanna on the Cybersyn SEC dataset.\\n\\n## A note on nomenclature\\n* **Foundational Model**: This is the underlying LLM\\n* **Context Model (aka Vanna Model)**: This is a layer that sits on top of the LLM and provides context to the LLM\\n* **Training**: Generally when we refer to \"training\" we\\'re talking about training the context model.\\n\\n## Contact Us\\nPing us on [Slack](https://join.slack.com/t/vanna-ai/shared_invite/zt-1unu0ipog-iE33QCoimQiBDxf2o7h97w), [Discord](https://discord.com/invite/qUZYKHremx), or [set up a 1:1 call](https://calendly.com/d/y7j-yqq-yz4/meet-with-both-vanna-co-founders) if you have any issues.\\n')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e41f238a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ").split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d28b1f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "891f848e",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_loader = GithubFileLoader(\n",
    "    repo=\"vanna-ai/vanna\",\n",
    "    branch=\"main\",\n",
    "    access_token=os.getenv('GITHUB_ACCESS_TOKEN'),\n",
    "    github_api_url=\"https://api.github.com\",\n",
    "    file_filter=lambda file_path: file_path.endswith(\".py\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6990ff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_docs = python_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e0ba880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(python_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "252a53e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "original = python_docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e0f5de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import re\\nfrom typing import List\\n\\nimport pandas as pd\\nfrom zhipuai import ZhipuAI\\n\\nfrom ..base import VannaBase\\n\\n\\nclass ZhipuAI_Chat(VannaBase):\\n    def __init__(self, config=None):\\n        VannaBase.__init__(self, config=config)\\n        if config is None:\\n            return\\n        if \"api_key\" not in config:\\n            raise Exception(\"Missing api_key in config\")\\n        self.api_key = config[\"api_key\"]\\n        self.model = config[\"model\"] if \"model\" in config else \"glm-4\"\\n        self.api_url = \"https://open.bigmodel.cn/api/paas/v4/chat/completions\"\\n\\n    # Static methods similar to those in ZhipuAI_Chat for message formatting and utility\\n    @staticmethod\\n    def system_message(message: str) -> dict:\\n        return {\"role\": \"system\", \"content\": message}\\n\\n    @staticmethod\\n    def user_message(message: str) -> dict:\\n        return {\"role\": \"user\", \"content\": message}\\n\\n    @staticmethod\\n    def assistant_message(message: str) -> dict:\\n        return {\"role\": \"assistant\", \"content\": message}\\n\\n    @staticmethod\\n    def str_to_approx_token_count(string: str) -> int:\\n        return len(string) / 4\\n\\n    @staticmethod\\n    def add_ddl_to_prompt(\\n        initial_prompt: str, ddl_list: List[str], max_tokens: int = 14000\\n    ) -> str:\\n        if len(ddl_list) > 0:\\n            initial_prompt += \"\\\\nYou may use the following DDL statements as a reference for what tables might be available. Use responses to past questions also to guide you:\\\\n\\\\n\"\\n\\n            for ddl in ddl_list:\\n                if (\\n                    ZhipuAI_Chat.str_to_approx_token_count(initial_prompt)\\n                    + ZhipuAI_Chat.str_to_approx_token_count(ddl)\\n                    < max_tokens\\n                ):\\n                    initial_prompt += f\"{ddl}\\\\n\\\\n\"\\n\\n        return initial_prompt\\n\\n    @staticmethod\\n    def add_documentation_to_prompt(\\n        initial_prompt: str, documentation_List: List[str], max_tokens: int = 14000\\n    ) -> str:\\n        if len(documentation_List) > 0:\\n            initial_prompt += \"\\\\nYou may use the following documentation as a reference for what tables might be available. Use responses to past questions also to guide you:\\\\n\\\\n\"\\n\\n            for documentation in documentation_List:\\n                if (\\n                    ZhipuAI_Chat.str_to_approx_token_count(initial_prompt)\\n                    + ZhipuAI_Chat.str_to_approx_token_count(documentation)\\n                    < max_tokens\\n                ):\\n                    initial_prompt += f\"{documentation}\\\\n\\\\n\"\\n\\n        return initial_prompt\\n\\n    @staticmethod\\n    def add_sql_to_prompt(\\n        initial_prompt: str, sql_List: List[str], max_tokens: int = 14000\\n    ) -> str:\\n        if len(sql_List) > 0:\\n            initial_prompt += \"\\\\nYou may use the following SQL statements as a reference for what tables might be available. Use responses to past questions also to guide you:\\\\n\\\\n\"\\n\\n            for question in sql_List:\\n                if (\\n                    ZhipuAI_Chat.str_to_approx_token_count(initial_prompt)\\n                    + ZhipuAI_Chat.str_to_approx_token_count(question[\"sql\"])\\n                    < max_tokens\\n                ):\\n                    initial_prompt += f\"{question[\\'question\\']}\\\\n{question[\\'sql\\']}\\\\n\\\\n\"\\n\\n        return initial_prompt\\n\\n    def get_sql_prompt(\\n        self,\\n        question: str,\\n        question_sql_list: List,\\n        ddl_list: List,\\n        doc_list: List,\\n        **kwargs,\\n    ):\\n        initial_prompt = \"The user provides a question and you provide SQL. You will only respond with SQL code and not with any explanations.\\\\n\\\\nRespond with only SQL code. Do not answer with any explanations -- just the code.\\\\n\"\\n\\n        initial_prompt = ZhipuAI_Chat.add_ddl_to_prompt(\\n            initial_prompt, ddl_list, max_tokens=14000\\n        )\\n\\n        initial_prompt = ZhipuAI_Chat.add_documentation_to_prompt(\\n            initial_prompt, doc_list, max_tokens=14000\\n        )\\n\\n        message_log = [ZhipuAI_Chat.system_message(initial_prompt)]\\n\\n        for example in question_sql_list:\\n            if example is None:\\n                print(\"example is None\")\\n            else:\\n                if example is not None and \"question\" in example and \"sql\" in example:\\n                    message_log.append(ZhipuAI_Chat.user_message(example[\"question\"]))\\n                    message_log.append(ZhipuAI_Chat.assistant_message(example[\"sql\"]))\\n\\n        message_log.append({\"role\": \"user\", \"content\": question})\\n\\n        return message_log\\n\\n    def get_followup_questions_prompt(\\n        self,\\n        question: str,\\n        df: pd.DataFrame,\\n        question_sql_list: List,\\n        ddl_list: List,\\n        doc_list: List,\\n        **kwargs,\\n    ):\\n        initial_prompt = f\"The user initially asked the question: \\'{question}\\': \\\\n\\\\n\"\\n\\n        initial_prompt = ZhipuAI_Chat.add_ddl_to_prompt(\\n            initial_prompt, ddl_list, max_tokens=14000\\n        )\\n\\n        initial_prompt = ZhipuAI_Chat.add_documentation_to_prompt(\\n            initial_prompt, doc_list, max_tokens=14000\\n        )\\n\\n        initial_prompt = ZhipuAI_Chat.add_sql_to_prompt(\\n            initial_prompt, question_sql_list, max_tokens=14000\\n        )\\n\\n        message_log = [ZhipuAI_Chat.system_message(initial_prompt)]\\n        message_log.append(\\n            ZhipuAI_Chat.user_message(\\n                \"Generate a List of followup questions that the user might ask about this data. Respond with a List of questions, one per line. Do not answer with any explanations -- just the questions.\"\\n            )\\n        )\\n\\n        return message_log\\n\\n    def generate_question(self, sql: str, **kwargs) -> str:\\n        response = self.submit_prompt(\\n            [\\n                self.system_message(\\n                    \"The user will give you SQL and you will try to guess what the business question this query is answering. Return just the question without any additional explanation. Do not reference the table name in the question.\"\\n                ),\\n                self.user_message(sql),\\n            ],\\n            **kwargs,\\n        )\\n\\n        return response\\n\\n    def _extract_python_code(self, markdown_string: str) -> str:\\n        # Regex pattern to match Python code blocks\\n        pattern = r\"```[\\\\w\\\\s]*python\\\\n([\\\\s\\\\S]*?)```|```([\\\\s\\\\S]*?)```\"\\n\\n        # Find all matches in the markdown string\\n        matches = re.findall(pattern, markdown_string, re.IGNORECASE)\\n\\n        # Extract the Python code from the matches\\n        python_code = []\\n        for match in matches:\\n            python = match[0] if match[0] else match[1]\\n            python_code.append(python.strip())\\n\\n        if len(python_code) == 0:\\n            return markdown_string\\n\\n        return python_code[0]\\n\\n    def _sanitize_plotly_code(self, raw_plotly_code: str) -> str:\\n        # Remove the fig.show() statement from the plotly code\\n        plotly_code = raw_plotly_code.replace(\"fig.show()\", \"\")\\n\\n        return plotly_code\\n\\n    def generate_plotly_code(\\n        self, question: str = None, sql: str = None, df_metadata: str = None, **kwargs\\n    ) -> str:\\n        if question is not None:\\n            system_msg = f\"The following is a pandas DataFrame that contains the results of the query that answers the question the user asked: \\'{question}\\'\"\\n        else:\\n            system_msg = \"The following is a pandas DataFrame \"\\n\\n        if sql is not None:\\n            system_msg += f\"\\\\n\\\\nThe DataFrame was produced using this query: {sql}\\\\n\\\\n\"\\n\\n        system_msg += f\"The following is information about the resulting pandas DataFrame \\'df\\': \\\\n{df_metadata}\"\\n\\n        message_log = [\\n            self.system_message(system_msg),\\n            self.user_message(\\n                \"Can you generate the Python plotly code to chart the results of the dataframe? Assume the data is in a pandas dataframe called \\'df\\'. If there is only one value in the dataframe, use an Indicator. Respond with only Python code. Do not answer with any explanations -- just the code.\"\\n            ),\\n        ]\\n\\n        plotly_code = self.submit_prompt(message_log, kwargs=kwargs)\\n\\n        return self._sanitize_plotly_code(self._extract_python_code(plotly_code))\\n\\n    def submit_prompt(\\n        self, prompt, max_tokens=500, temperature=0.7, top_p=0.7, stop=None, **kwargs\\n    ):\\n        if prompt is None:\\n            raise Exception(\"Prompt is None\")\\n\\n        if len(prompt) == 0:\\n            raise Exception(\"Prompt is empty\")\\n\\n        client = ZhipuAI(api_key=self.api_key)\\n        response = client.chat.completions.create(\\n            model=\"glm-4\",\\n            max_tokens=max_tokens,\\n            temperature=temperature,\\n            top_p=top_p,\\n            stop=stop,\\n            messages=prompt,\\n        )\\n\\n        return response.choices[0].message.content\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af1fb6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_docs[0].page_content = \"This is a new content\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d27420ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'path': 'src/vanna/ZhipuAI/ZhipuAI_Chat.py', 'sha': 'c9181b0295e6a54763075579f82eee8113091b06', 'source': 'https://api.github.com/vanna-ai/vanna/blob/main/src/vanna/ZhipuAI/ZhipuAI_Chat.py'}, page_content='This is a new content')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc77ad0b",
   "metadata": {},
   "source": [
    "#### DocString and Comment Line Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fce7e7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f590d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4o_mini_model = AzureChatOpenAI(\n",
    "    api_version=\"2024-10-21\",\n",
    "    azure_deployment=\"gpt-4o-mini-2024-07-18\",\n",
    "    temperature=0,\n",
    "    max_tokens=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bba70519",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_string_sys_message = \"You are a DocString and commentline generator. \" \\\n",
    "    \"You will be given a code snippet and you will generate a docstring and comment lines for the code. \" \\\n",
    "    \"Return the provided code snippet with the docstring and comment lines added. \" \\\n",
    "    \"The docstring should be in the format of a Python docstring. \" \\\n",
    "    \"The comment lines should be in the format of Python comments. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af0d59a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import re\\nfrom typing import List\\n\\nimport pandas as pd\\nfrom zhipuai import ZhipuAI\\n\\nfrom ..base import VannaBase\\n\\n\\nclass ZhipuAI_Chat(VannaBase):\\n    def __init__(self, config=None):\\n        VannaBase.__init__(self, config=config)\\n        if config is None:\\n            return\\n        if \"api_key\" not in config:\\n            raise Exception(\"Missing api_key in config\")\\n        self.api_key = config[\"api_key\"]\\n        self.model = config[\"model\"] if \"model\" in config else \"glm-4\"\\n        self.api_url = \"https://open.bigmodel.cn/api/paas/v4/chat/completions\"\\n\\n    # Static methods similar to those in ZhipuAI_Chat for message formatting and utility\\n    @staticmethod\\n    def system_message(message: str) -> dict:\\n        return {\"role\": \"system\", \"content\": message}\\n\\n    @staticmethod\\n    def user_message(message: str) -> dict:\\n        return {\"role\": \"user\", \"content\": message}\\n\\n    @staticmethod\\n    def assistant_message(message: str) -> dict:\\n        return {\"role\": \"assistant\", \"content\": message}\\n\\n    @staticmethod\\n    def str_to_approx_token_count(string: str) -> int:\\n        return len(string) / 4\\n\\n    @staticmethod\\n    def add_ddl_to_prompt(\\n        initial_prompt: str, ddl_list: List[str], max_tokens: int = 14000\\n    ) -> str:\\n        if len(ddl_list) > 0:\\n            initial_prompt += \"\\\\nYou may use the following DDL statements as a reference for what tables might be available. Use responses to past questions also to guide you:\\\\n\\\\n\"\\n\\n            for ddl in ddl_list:\\n                if (\\n                    ZhipuAI_Chat.str_to_approx_token_count(initial_prompt)\\n                    + ZhipuAI_Chat.str_to_approx_token_count(ddl)\\n                    < max_tokens\\n                ):\\n                    initial_prompt += f\"{ddl}\\\\n\\\\n\"\\n\\n        return initial_prompt\\n\\n    @staticmethod\\n    def add_documentation_to_prompt(\\n        initial_prompt: str, documentation_List: List[str], max_tokens: int = 14000\\n    ) -> str:\\n        if len(documentation_List) > 0:\\n            initial_prompt += \"\\\\nYou may use the following documentation as a reference for what tables might be available. Use responses to past questions also to guide you:\\\\n\\\\n\"\\n\\n            for documentation in documentation_List:\\n                if (\\n                    ZhipuAI_Chat.str_to_approx_token_count(initial_prompt)\\n                    + ZhipuAI_Chat.str_to_approx_token_count(documentation)\\n                    < max_tokens\\n                ):\\n                    initial_prompt += f\"{documentation}\\\\n\\\\n\"\\n\\n        return initial_prompt\\n\\n    @staticmethod\\n    def add_sql_to_prompt(\\n        initial_prompt: str, sql_List: List[str], max_tokens: int = 14000\\n    ) -> str:\\n        if len(sql_List) > 0:\\n            initial_prompt += \"\\\\nYou may use the following SQL statements as a reference for what tables might be available. Use responses to past questions also to guide you:\\\\n\\\\n\"\\n\\n            for question in sql_List:\\n                if (\\n                    ZhipuAI_Chat.str_to_approx_token_count(initial_prompt)\\n                    + ZhipuAI_Chat.str_to_approx_token_count(question[\"sql\"])\\n                    < max_tokens\\n                ):\\n                    initial_prompt += f\"{question[\\'question\\']}\\\\n{question[\\'sql\\']}\\\\n\\\\n\"\\n\\n        return initial_prompt\\n\\n    def get_sql_prompt(\\n        self,\\n        question: str,\\n        question_sql_list: List,\\n        ddl_list: List,\\n        doc_list: List,\\n        **kwargs,\\n    ):\\n        initial_prompt = \"The user provides a question and you provide SQL. You will only respond with SQL code and not with any explanations.\\\\n\\\\nRespond with only SQL code. Do not answer with any explanations -- just the code.\\\\n\"\\n\\n        initial_prompt = ZhipuAI_Chat.add_ddl_to_prompt(\\n            initial_prompt, ddl_list, max_tokens=14000\\n        )\\n\\n        initial_prompt = ZhipuAI_Chat.add_documentation_to_prompt(\\n            initial_prompt, doc_list, max_tokens=14000\\n        )\\n\\n        message_log = [ZhipuAI_Chat.system_message(initial_prompt)]\\n\\n        for example in question_sql_list:\\n            if example is None:\\n                print(\"example is None\")\\n            else:\\n                if example is not None and \"question\" in example and \"sql\" in example:\\n                    message_log.append(ZhipuAI_Chat.user_message(example[\"question\"]))\\n                    message_log.append(ZhipuAI_Chat.assistant_message(example[\"sql\"]))\\n\\n        message_log.append({\"role\": \"user\", \"content\": question})\\n\\n        return message_log\\n\\n    def get_followup_questions_prompt(\\n        self,\\n        question: str,\\n        df: pd.DataFrame,\\n        question_sql_list: List,\\n        ddl_list: List,\\n        doc_list: List,\\n        **kwargs,\\n    ):\\n        initial_prompt = f\"The user initially asked the question: \\'{question}\\': \\\\n\\\\n\"\\n\\n        initial_prompt = ZhipuAI_Chat.add_ddl_to_prompt(\\n            initial_prompt, ddl_list, max_tokens=14000\\n        )\\n\\n        initial_prompt = ZhipuAI_Chat.add_documentation_to_prompt(\\n            initial_prompt, doc_list, max_tokens=14000\\n        )\\n\\n        initial_prompt = ZhipuAI_Chat.add_sql_to_prompt(\\n            initial_prompt, question_sql_list, max_tokens=14000\\n        )\\n\\n        message_log = [ZhipuAI_Chat.system_message(initial_prompt)]\\n        message_log.append(\\n            ZhipuAI_Chat.user_message(\\n                \"Generate a List of followup questions that the user might ask about this data. Respond with a List of questions, one per line. Do not answer with any explanations -- just the questions.\"\\n            )\\n        )\\n\\n        return message_log\\n\\n    def generate_question(self, sql: str, **kwargs) -> str:\\n        response = self.submit_prompt(\\n            [\\n                self.system_message(\\n                    \"The user will give you SQL and you will try to guess what the business question this query is answering. Return just the question without any additional explanation. Do not reference the table name in the question.\"\\n                ),\\n                self.user_message(sql),\\n            ],\\n            **kwargs,\\n        )\\n\\n        return response\\n\\n    def _extract_python_code(self, markdown_string: str) -> str:\\n        # Regex pattern to match Python code blocks\\n        pattern = r\"```[\\\\w\\\\s]*python\\\\n([\\\\s\\\\S]*?)```|```([\\\\s\\\\S]*?)```\"\\n\\n        # Find all matches in the markdown string\\n        matches = re.findall(pattern, markdown_string, re.IGNORECASE)\\n\\n        # Extract the Python code from the matches\\n        python_code = []\\n        for match in matches:\\n            python = match[0] if match[0] else match[1]\\n            python_code.append(python.strip())\\n\\n        if len(python_code) == 0:\\n            return markdown_string\\n\\n        return python_code[0]\\n\\n    def _sanitize_plotly_code(self, raw_plotly_code: str) -> str:\\n        # Remove the fig.show() statement from the plotly code\\n        plotly_code = raw_plotly_code.replace(\"fig.show()\", \"\")\\n\\n        return plotly_code\\n\\n    def generate_plotly_code(\\n        self, question: str = None, sql: str = None, df_metadata: str = None, **kwargs\\n    ) -> str:\\n        if question is not None:\\n            system_msg = f\"The following is a pandas DataFrame that contains the results of the query that answers the question the user asked: \\'{question}\\'\"\\n        else:\\n            system_msg = \"The following is a pandas DataFrame \"\\n\\n        if sql is not None:\\n            system_msg += f\"\\\\n\\\\nThe DataFrame was produced using this query: {sql}\\\\n\\\\n\"\\n\\n        system_msg += f\"The following is information about the resulting pandas DataFrame \\'df\\': \\\\n{df_metadata}\"\\n\\n        message_log = [\\n            self.system_message(system_msg),\\n            self.user_message(\\n                \"Can you generate the Python plotly code to chart the results of the dataframe? Assume the data is in a pandas dataframe called \\'df\\'. If there is only one value in the dataframe, use an Indicator. Respond with only Python code. Do not answer with any explanations -- just the code.\"\\n            ),\\n        ]\\n\\n        plotly_code = self.submit_prompt(message_log, kwargs=kwargs)\\n\\n        return self._sanitize_plotly_code(self._extract_python_code(plotly_code))\\n\\n    def submit_prompt(\\n        self, prompt, max_tokens=500, temperature=0.7, top_p=0.7, stop=None, **kwargs\\n    ):\\n        if prompt is None:\\n            raise Exception(\"Prompt is None\")\\n\\n        if len(prompt) == 0:\\n            raise Exception(\"Prompt is empty\")\\n\\n        client = ZhipuAI(api_key=self.api_key)\\n        response = client.chat.completions.create(\\n            model=\"glm-4\",\\n            max_tokens=max_tokens,\\n            temperature=temperature,\\n            top_p=top_p,\\n            stop=stop,\\n            messages=prompt,\\n        )\\n\\n        return response.choices[0].message.content\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bcb7e163",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=doc_string_sys_message),\n",
    "    HumanMessage(content=python_docs[0].page_content)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d3b5f37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = gpt4o_mini_model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7d4359c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='```python\\nimport re\\nfrom typing import List\\n\\nimport pandas as pd\\nfrom zhipuai import ZhipuAI\\n\\nfrom ..base import VannaBase\\n\\n\\nclass ZhipuAI_Chat(VannaBase):\\n    \"\"\"\\n    A class to interact with the ZhipuAI API for generating SQL queries and follow-up questions based on user input.\\n    \\n    This class extends the VannaBase class and provides methods to format messages, \\n    add context to prompts, and generate SQL and Plotly code based on user questions.\\n    \\n    Attributes:\\n        api_key (str): The API key for authenticating with the ZhipuAI service.\\n        model (str): The model to be used for generating responses.\\n        api_url (str): The URL for the ZhipuAI API endpoint.\\n    \"\"\"\\n\\n    def __init__(self, config=None):\\n        \"\"\"\\n        Initializes the ZhipuAI_Chat instance with the provided configuration.\\n\\n        Args:\\n            config (dict, optional): Configuration dictionary containing \\'api_key\\' and \\'model\\'.\\n        \\n        Raises:\\n            Exception: If \\'api_key\\' is missing in the configuration.\\n        \"\"\"\\n        VannaBase.__init__(self, config=config)\\n        # Check if the configuration is provided\\n        if config is None:\\n            return\\n        # Ensure that the API key is present in the configuration\\n        if \"api_key\" not in config:\\n            raise Exception(\"Missing api_key in config\")\\n        self.api_key = config[\"api_key\"]\\n        # Set the model to use, defaulting to \"glm-4\" if not specified\\n        self.model = config[\"model\"] if \"model\" in config else \"glm-4\"\\n        self.api_url = \"https://open.bigmodel.cn/api/paas/v4/chat/completions\"\\n\\n    @staticmethod\\n    def system_message(message: str) -> dict:\\n        \"\"\"\\n        Formats a system message for the chat.\\n\\n        Args:\\n            message (str): The content of the system message.\\n\\n        Returns:\\n            dict: A dictionary representing the system message.\\n        \"\"\"\\n        return {\"role\": \"system\", \"content\": message}\\n\\n    @staticmethod\\n    def user_message(message: str) -> dict:\\n        \"\"\"\\n        Formats a user message for the chat.\\n\\n        Args:\\n            message (str): The content of the user message.\\n\\n        Returns:\\n            dict: A dictionary representing the user message.\\n        \"\"\"\\n        return {\"role\": \"user\", \"content\": message}\\n\\n    @staticmethod\\n    def assistant_message(message: str) -> dict:\\n        \"\"\"\\n        Formats an assistant message for the chat.\\n\\n        Args:\\n            message (str): The content of the assistant message.\\n\\n        Returns:\\n            dict: A dictionary representing the assistant message.\\n        \"\"\"\\n        return {\"role\": \"assistant\", \"content\": message}\\n\\n    @staticmethod\\n    def str_to_approx_token_count(string: str) -> int:\\n        \"\"\"\\n        Estimates the token count of a given string.\\n\\n        Args:\\n            string (str): The string to estimate the token count for.\\n\\n        Returns:\\n            int: The estimated token count.\\n        \"\"\"\\n        return len(string) / 4\\n\\n    @staticmethod\\n    def add_ddl_to_prompt(\\n        initial_prompt: str, ddl_list: List[str], max_tokens: int = 14000\\n    ) -> str:\\n        \"\"\"\\n        Adds DDL statements to the initial prompt.\\n\\n        Args:\\n            initial_prompt (str): The initial prompt to which DDL statements will be added.\\n            ddl_list (List[str]): A list of DDL statements to include.\\n            max_tokens (int, optional): The maximum token limit for the prompt.\\n\\n        Returns:\\n            str: The updated prompt with DDL statements included.\\n        \"\"\"\\n        if len(ddl_list) > 0:\\n            initial_prompt += \"\\\\nYou may use the following DDL statements as a reference for what tables might be available. Use responses to past questions also to guide you:\\\\n\\\\n\"\\n\\n            for ddl in ddl_list:\\n                # Check if adding the DDL statement exceeds the max token limit\\n                if (\\n                    ZhipuAI_Chat.str_to_approx_token_count(initial_prompt)\\n                    + ZhipuAI_Chat.str_to_approx_token_count(ddl)\\n                    < max_tokens\\n                ):\\n                    initial_prompt += f\"{ddl}\\\\n\\\\n\"\\n\\n        return initial_prompt\\n\\n    @staticmethod\\n    def add_documentation_to_prompt(\\n        initial_prompt: str, documentation_List: List[str], max_tokens: int = 14000\\n    ) -> str:\\n        \"\"\"\\n        Adds documentation references to the initial prompt.\\n\\n        Args:\\n            initial_prompt (str): The initial prompt to which documentation will be added.\\n            documentation_List (List[str]): A list of documentation references to include.\\n            max_tokens (int, optional): The maximum token limit for the prompt.\\n\\n        Returns:\\n            str: The updated prompt with documentation included.\\n        \"\"\"\\n        if len(documentation_List) > 0:\\n            initial_prompt += \"\\\\nYou may use the following documentation as a reference for what tables might be available. Use responses to past questions also to guide you:\\\\n\\\\n\"\\n\\n            for documentation in documentation_List:\\n                # Check if adding the documentation exceeds the max token limit\\n                if (\\n                    ZhipuAI_Chat.str_to_approx_token_count(initial_prompt)\\n                    + ZhipuAI_Chat.str_to_approx_token_count(documentation)\\n                    < max_tokens\\n                ):\\n                    initial_prompt += f\"{documentation}\\\\n\\\\n\"\\n\\n        return initial_prompt\\n\\n    @staticmethod\\n    def add_sql_to_prompt(\\n        initial_prompt: str, sql_List: List[str], max_tokens: int = 14000\\n    ) -> str:\\n        \"\"\"\\n        Adds SQL statements to the initial prompt.\\n\\n        Args:\\n            initial_prompt (str): The initial prompt to which SQL statements will be added.\\n            sql_List (List[str]): A list of SQL statements to include.\\n            max_tokens (int, optional): The maximum token limit for the prompt.\\n\\n        Returns:\\n            str: The updated prompt with SQL statements included.\\n        \"\"\"\\n        if len(sql_List) > 0:\\n            initial_prompt += \"\\\\nYou may use the following SQL statements as a reference for what tables might be available. Use responses to past questions also to guide you:\\\\n\\\\n\"\\n\\n            for question in sql_List:\\n                # Check if adding the SQL statement exceeds the max token limit\\n                if (\\n                    ZhipuAI_Chat.str_to_approx_token_count(initial_prompt)\\n                    + ZhipuAI_Chat.str_to_approx_token_count(question[\"sql\"])\\n                    < max_tokens\\n                ):\\n                    initial_prompt += f\"{question[\\'question\\']}\\\\n{question[\\'sql\\']}\\\\n\\\\n\"\\n\\n        return initial_prompt\\n\\n    def get_sql_prompt(\\n        self,\\n        question: str,\\n        question_sql_list: List,\\n        ddl_list: List,\\n        doc_list: List,\\n        **kwargs,\\n    ):\\n        \"\"\"\\n        Constructs a prompt for generating SQL based on the user\\'s question and context.\\n\\n        Args:\\n            question (str): The user\\'s question for which SQL is to be generated.\\n            question_sql_list (List): A list of previous question-SQL pairs for context.\\n            ddl_list (List): A list of DDL statements for reference.\\n            doc_list (List): A list of documentation references for context.\\n            **kwargs: Additional arguments for flexibility.\\n\\n        Returns:\\n            list: A message log containing the formatted messages for the chat.\\n        \"\"\"\\n        initial_prompt = \"The user provides a question and you provide SQL. You will only respond with SQL code and not with any explanations.\\\\n\\\\nRespond with only SQL code. Do not answer with any explanations -- just the code.\\\\n\"\\n\\n        # Add DDL, documentation, and SQL context to the initial prompt\\n        initial_prompt = ZhipuAI_Chat.add_ddl_to_prompt(\\n            initial_prompt, ddl_list, max_tokens=14000\\n        )\\n\\n        initial_prompt = ZhipuAI_Chat.add_documentation_to_prompt(\\n            initial_prompt, doc_list, max_tokens=14000\\n        )\\n\\n        message_log = [ZhipuAI_Chat.system_message(initial_prompt)]\\n\\n        for example in question_sql_list:\\n            if example is None:\\n                print(\"example is None\")\\n            else:\\n                if example is not None and \"question\" in example and \"sql\" in example:\\n                    message_log.append(ZhipuAI_Chat.user_message(example[\"question\"]))\\n                    message_log.append(ZhipuAI_Chat.assistant_message(example[\"sql\"]))\\n\\n        message_log.append({\"role\": \"user\", \"content\": question})\\n\\n        return message_log\\n\\n    def get_followup_questions_prompt(\\n        self,\\n        question: str,\\n        df: pd.DataFrame,\\n        question_sql_list: List,\\n        ddl_list: List,\\n        doc_list: List,\\n        **kwargs,\\n    ):\\n        \"\"\"\\n        Constructs a prompt for generating follow-up questions based on the user\\'s initial question and context.\\n\\n        Args:\\n            question (str): The user\\'s initial question.\\n            df (pd.DataFrame): The DataFrame containing query results.\\n            question_sql_list (List): A list of previous question-SQL pairs for context.\\n            ddl_list (List): A list of DDL statements for reference.\\n            doc_list (List): A list of documentation references for context.\\n            **kwargs: Additional arguments for flexibility.\\n\\n        Returns:\\n            list: A message log containing the formatted messages for the chat.\\n        \"\"\"\\n        initial_prompt = f\"The user initially asked the question: \\'{question}\\': \\\\n\\\\n\"\\n\\n        # Add DDL, documentation, and SQL context to the initial prompt\\n        initial_prompt = ZhipuAI_Chat.add_ddl_to_prompt(\\n           ', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2000, 'prompt_tokens': 2019, 'total_tokens': 4019, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b705f0c291', 'id': 'chatcmpl-BL2bnw2BECDWIhE60LV8AZhJpkOMz', 'finish_reason': 'length', 'logprobs': None, 'content_filter_results': {}}, id='run-8f725555-737d-4480-9320-48cadc7ddf19-0', usage_metadata={'input_tokens': 2019, 'output_tokens': 2000, 'total_tokens': 4019, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cb4cdef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No sentence-transformers model found with name microsoft/codebert-base. Creating a new one with mean pooling.\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embedding_python = HuggingFaceEmbeddings(\n",
    "        model_name=\"microsoft/codebert-base\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18a1b4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON,\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f5a9dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_chunks = python_splitter.split_documents(python_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c4aad79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2180"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(python_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6608d029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class ZhipuAI_Chat(VannaBase):\\n    def __init__(self, config=None):\\n        VannaBase.__init__(self, config=config)\\n        if config is None:\\n            return\\n        if \"api_key\" not in config:\\n            raise Exception(\"Missing api_key in config\")\\n        self.api_key = config[\"api_key\"]\\n        self.model = config[\"model\"] if \"model\" in config else \"glm-4\"\\n        self.api_url = \"https://open.bigmodel.cn/api/paas/v4/chat/completions\"'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_chunks[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7e473516",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=doc_string_sys_message),\n",
    "    HumanMessage(content=python_chunks[1].page_content)\n",
    "]\n",
    "response = gpt4o_mini_model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d037a850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='```python\\nclass ZhipuAI_Chat(VannaBase):\\n    \"\"\"\\n    ZhipuAI_Chat is a subclass of VannaBase that initializes a chat model \\n    using the provided configuration. It checks for the presence of an API key \\n    and sets default values for the model if not specified.\\n\\n    Attributes:\\n        api_key (str): The API key for authenticating requests.\\n        model (str): The model to be used for chat completions, defaults to \"glm-4\".\\n        api_url (str): The URL endpoint for the chat completions API.\\n    \"\"\"\\n\\n    def __init__(self, config=None):\\n        \"\"\"\\n        Initializes the ZhipuAI_Chat instance.\\n\\n        Args:\\n            config (dict, optional): A configuration dictionary that may contain \\n                                      \\'api_key\\' and \\'model\\'. If None, defaults \\n                                      will be used.\\n\\n        Raises:\\n            Exception: If \\'api_key\\' is not present in the configuration.\\n        \"\"\"\\n        # Call the parent class\\'s initializer\\n        VannaBase.__init__(self, config=config)\\n        \\n        # If no configuration is provided, exit the initializer\\n        if config is None:\\n            return\\n        \\n        # Check if \\'api_key\\' is present in the configuration\\n        if \"api_key\" not in config:\\n            raise Exception(\"Missing api_key in config\")\\n        \\n        # Set the API key from the configuration\\n        self.api_key = config[\"api_key\"]\\n        \\n        # Set the model from the configuration or default to \"glm-4\"\\n        self.model = config[\"model\"] if \"model\" in config else \"glm-4\"\\n        \\n        # Define the API URL for chat completions\\n        self.api_url = \"https://open.bigmodel.cn/api/paas/v4/chat/completions\"\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 372, 'prompt_tokens': 198, 'total_tokens': 570, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b705f0c291', 'id': 'chatcmpl-BL2dmu4FlDeGsOF7pbmvL2BCQLzkj', 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {}}, id='run-ec60c0d9-a500-4997-82e3-443d17644805-0', usage_metadata={'input_tokens': 198, 'output_tokens': 372, 'total_tokens': 570, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "476637da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.3975783586502075,\n",
       " 0.2779819965362549,\n",
       " 0.26995208859443665,\n",
       " -0.04889015108346939,\n",
       " -0.46771231293678284,\n",
       " -0.7078947424888611,\n",
       " -0.1644677221775055,\n",
       " 0.38149964809417725,\n",
       " 0.5058804154396057,\n",
       " 0.6304805874824524,\n",
       " -0.32642263174057007,\n",
       " 0.8396518230438232,\n",
       " -0.30033883452415466,\n",
       " -0.1489625871181488,\n",
       " 0.8165978193283081,\n",
       " -0.033967651426792145,\n",
       " 0.2845640778541565,\n",
       " 0.41337040066719055,\n",
       " -0.07939557731151581,\n",
       " 0.30950579047203064,\n",
       " -0.3646925091743469,\n",
       " -0.23856252431869507,\n",
       " 0.6692246794700623,\n",
       " -0.5027076601982117,\n",
       " 0.6458678841590881,\n",
       " 0.4917256534099579,\n",
       " -0.12268109619617462,\n",
       " 0.8833966255187988,\n",
       " -0.5978009700775146,\n",
       " 0.7823993563652039,\n",
       " -0.2443632185459137,\n",
       " 0.014729096554219723,\n",
       " 1.1373494863510132,\n",
       " 0.3672619163990021,\n",
       " 0.4696651101112366,\n",
       " -0.396048367023468,\n",
       " -0.36577120423316956,\n",
       " 0.22262990474700928,\n",
       " 0.04493819922208786,\n",
       " -0.43121054768562317,\n",
       " -0.1105307936668396,\n",
       " 0.5286081433296204,\n",
       " -0.8674601912498474,\n",
       " -0.10306952893733978,\n",
       " 0.5286516547203064,\n",
       " 0.35676631331443787,\n",
       " 0.5339787602424622,\n",
       " -0.3401283323764801,\n",
       " -0.07374509423971176,\n",
       " 0.7085483074188232,\n",
       " 0.6777699589729309,\n",
       " 0.4178248643875122,\n",
       " -0.444702684879303,\n",
       " -0.16961149871349335,\n",
       " 0.6013423204421997,\n",
       " 0.6848514080047607,\n",
       " -1.0446749925613403,\n",
       " -0.9819852113723755,\n",
       " -0.18805865943431854,\n",
       " -0.7120919227600098,\n",
       " -0.2208413928747177,\n",
       " -0.05556148663163185,\n",
       " -0.4302721917629242,\n",
       " -0.4559340476989746,\n",
       " 1.1145501136779785,\n",
       " 0.28409484028816223,\n",
       " 0.5777214169502258,\n",
       " 0.6562206745147705,\n",
       " -0.06328899413347244,\n",
       " 0.4342139661312103,\n",
       " -0.22448371350765228,\n",
       " -0.5917275547981262,\n",
       " -0.2582733929157257,\n",
       " -0.39343127608299255,\n",
       " -0.7020600438117981,\n",
       " 0.7860215902328491,\n",
       " -0.26381972432136536,\n",
       " -6.73375129699707,\n",
       " 0.2785530090332031,\n",
       " 0.6764807105064392,\n",
       " 0.42470782995224,\n",
       " -0.6954987645149231,\n",
       " 2.3344154357910156,\n",
       " 0.6263306140899658,\n",
       " -0.759347140789032,\n",
       " 0.439094215631485,\n",
       " 0.06967616826295853,\n",
       " 0.19490118324756622,\n",
       " -0.6019472479820251,\n",
       " -0.19963529706001282,\n",
       " 0.32895517349243164,\n",
       " 0.04520903527736664,\n",
       " 0.3787010908126831,\n",
       " 0.9197698831558228,\n",
       " -0.265075147151947,\n",
       " 0.8947501182556152,\n",
       " 0.5380462408065796,\n",
       " -0.3541082441806793,\n",
       " 0.13134664297103882,\n",
       " -0.47988343238830566,\n",
       " -0.3242560625076294,\n",
       " -0.6015718579292297,\n",
       " 0.8647528290748596,\n",
       " 0.5297046303749084,\n",
       " 0.26352059841156006,\n",
       " -0.6579475402832031,\n",
       " 0.27363085746765137,\n",
       " -0.9559628963470459,\n",
       " 0.4375765919685364,\n",
       " -0.3385474383831024,\n",
       " -0.06720377504825592,\n",
       " -0.5379801988601685,\n",
       " 1.065988540649414,\n",
       " 0.2344629317522049,\n",
       " 0.3071020841598511,\n",
       " -0.48756808042526245,\n",
       " 0.40938401222229004,\n",
       " 0.24575550854206085,\n",
       " 0.06264612823724747,\n",
       " -0.08846273273229599,\n",
       " -0.5985385775566101,\n",
       " 0.271139919757843,\n",
       " -0.3535993993282318,\n",
       " 0.695842981338501,\n",
       " -0.3823748230934143,\n",
       " 0.21600504219532013,\n",
       " -0.31572985649108887,\n",
       " 0.25711604952812195,\n",
       " -0.01585630141198635,\n",
       " 0.1525043100118637,\n",
       " -0.809070348739624,\n",
       " -1.031389594078064,\n",
       " -0.28931400179862976,\n",
       " 0.8454554080963135,\n",
       " 0.5841096639633179,\n",
       " -0.8073030114173889,\n",
       " 0.509107768535614,\n",
       " 0.060216955840587616,\n",
       " -0.46007058024406433,\n",
       " 0.46757772564888,\n",
       " -0.5088245272636414,\n",
       " -0.5900819897651672,\n",
       " -0.27438122034072876,\n",
       " 0.04632691666483879,\n",
       " 0.8874285221099854,\n",
       " -0.0679778978228569,\n",
       " -0.022815724834799767,\n",
       " 0.5411586761474609,\n",
       " 0.42761513590812683,\n",
       " -0.46819794178009033,\n",
       " -0.7734074592590332,\n",
       " 0.1260061264038086,\n",
       " 1.0016425848007202,\n",
       " -0.09336862713098526,\n",
       " 0.07680672407150269,\n",
       " -1.6650500297546387,\n",
       " -0.1290876865386963,\n",
       " 0.5552200078964233,\n",
       " 0.4737011790275574,\n",
       " -0.14978323876857758,\n",
       " 0.44707971811294556,\n",
       " -0.14894533157348633,\n",
       " -0.02634725160896778,\n",
       " 0.5529237389564514,\n",
       " 0.6265397071838379,\n",
       " 0.15002237260341644,\n",
       " -0.4130030572414398,\n",
       " 0.09673261642456055,\n",
       " 0.5261594653129578,\n",
       " 0.9593799114227295,\n",
       " -0.44861072301864624,\n",
       " -0.4037349820137024,\n",
       " -0.6800334453582764,\n",
       " -0.10622237622737885,\n",
       " 0.49950170516967773,\n",
       " 0.8167184591293335,\n",
       " 0.2848140597343445,\n",
       " -0.21460877358913422,\n",
       " -0.3915378451347351,\n",
       " 0.983887255191803,\n",
       " 0.5722550749778748,\n",
       " -0.3752545118331909,\n",
       " 0.30009546875953674,\n",
       " -0.6437017321586609,\n",
       " -0.4109629690647125,\n",
       " 0.2616136968135834,\n",
       " -0.35376331210136414,\n",
       " 0.8313948512077332,\n",
       " -0.10589141398668289,\n",
       " -0.07514128088951111,\n",
       " -0.3349260091781616,\n",
       " -0.4075686037540436,\n",
       " 0.20557555556297302,\n",
       " 0.7678057551383972,\n",
       " 0.1295396089553833,\n",
       " 0.2912214696407318,\n",
       " -0.076205775141716,\n",
       " 0.4207216203212738,\n",
       " 0.8824516534805298,\n",
       " 0.19829706847667694,\n",
       " -0.34162431955337524,\n",
       " 1.1623622179031372,\n",
       " 0.6761417984962463,\n",
       " 0.5078383684158325,\n",
       " 0.20199362933635712,\n",
       " 0.2383522391319275,\n",
       " -0.3018347918987274,\n",
       " 0.5614548325538635,\n",
       " 0.5639224052429199,\n",
       " 1.219649076461792,\n",
       " 1.4306387901306152,\n",
       " -0.2054048627614975,\n",
       " 0.1789332926273346,\n",
       " -0.65765780210495,\n",
       " -0.5870130658149719,\n",
       " 0.12301383167505264,\n",
       " -0.752257227897644,\n",
       " -1.402719497680664,\n",
       " -0.6420936584472656,\n",
       " -0.3733058273792267,\n",
       " -1.2082244157791138,\n",
       " 0.3233492970466614,\n",
       " -0.22150856256484985,\n",
       " -0.22446425259113312,\n",
       " -0.27453964948654175,\n",
       " -0.10471650958061218,\n",
       " 0.42399322986602783,\n",
       " -0.38691794872283936,\n",
       " -0.35472869873046875,\n",
       " 0.35729628801345825,\n",
       " -0.34093624353408813,\n",
       " -0.4326402246952057,\n",
       " -1.0514965057373047,\n",
       " -0.3446277678012848,\n",
       " 0.16910669207572937,\n",
       " -0.44587647914886475,\n",
       " -0.5906124114990234,\n",
       " 0.4638681709766388,\n",
       " 0.48382726311683655,\n",
       " -0.8949261903762817,\n",
       " 0.0973992794752121,\n",
       " 0.32035744190216064,\n",
       " 0.8625013828277588,\n",
       " 1.0094798803329468,\n",
       " -0.05425605550408363,\n",
       " -0.5446476936340332,\n",
       " 0.3757518231868744,\n",
       " -0.05948230251669884,\n",
       " 0.6999980211257935,\n",
       " 0.5657079219818115,\n",
       " 0.29904812574386597,\n",
       " 0.568210780620575,\n",
       " 0.4691529870033264,\n",
       " -0.33272695541381836,\n",
       " 0.02290298230946064,\n",
       " -0.4270937442779541,\n",
       " -0.17595504224300385,\n",
       " -0.6332253813743591,\n",
       " 0.8959164619445801,\n",
       " 1.441199779510498,\n",
       " 0.4719659686088562,\n",
       " 0.06244375556707382,\n",
       " 0.762061595916748,\n",
       " -0.5917286276817322,\n",
       " 0.3234846889972687,\n",
       " 0.22905400395393372,\n",
       " 0.558651864528656,\n",
       " 0.5040261745452881,\n",
       " 0.7952731847763062,\n",
       " 0.36055758595466614,\n",
       " 1.0495295524597168,\n",
       " 0.3268808126449585,\n",
       " -0.5290709137916565,\n",
       " 0.37065446376800537,\n",
       " 0.30442842841148376,\n",
       " 0.20261266827583313,\n",
       " 0.183323472738266,\n",
       " 0.33216947317123413,\n",
       " -0.8720996379852295,\n",
       " -0.30239924788475037,\n",
       " -0.7036210894584656,\n",
       " -0.6238242387771606,\n",
       " 0.9245273470878601,\n",
       " -0.00644309725612402,\n",
       " -0.33472180366516113,\n",
       " -0.2920442223548889,\n",
       " 0.007239714730530977,\n",
       " 0.8299090266227722,\n",
       " -0.025490887463092804,\n",
       " -0.04559602960944176,\n",
       " 0.27961450815200806,\n",
       " -0.32916510105133057,\n",
       " 0.8169409036636353,\n",
       " 0.1558547466993332,\n",
       " -0.2052728831768036,\n",
       " 0.4869731068611145,\n",
       " 0.6547645330429077,\n",
       " 0.5519148111343384,\n",
       " 0.40249428153038025,\n",
       " -0.6370957493782043,\n",
       " 0.2346169501543045,\n",
       " 0.3577057719230652,\n",
       " -0.189594566822052,\n",
       " 0.1113499104976654,\n",
       " -0.19756212830543518,\n",
       " -0.7189981341362,\n",
       " -0.10135873407125473,\n",
       " 0.38106080889701843,\n",
       " 0.29708918929100037,\n",
       " -0.25437548756599426,\n",
       " 0.29436594247817993,\n",
       " -0.9078809022903442,\n",
       " -0.37879660725593567,\n",
       " 0.01036133710294962,\n",
       " 0.3488938808441162,\n",
       " -0.21399326622486115,\n",
       " -0.18049898743629456,\n",
       " -0.019368911162018776,\n",
       " -0.5076098442077637,\n",
       " 0.4564032554626465,\n",
       " 0.48550647497177124,\n",
       " -0.1746405065059662,\n",
       " 0.891071617603302,\n",
       " -0.7906231880187988,\n",
       " 0.7118741273880005,\n",
       " 0.8715108036994934,\n",
       " -0.6736019253730774,\n",
       " -0.8930234909057617,\n",
       " -1.257036566734314,\n",
       " -0.3562791347503662,\n",
       " -0.911815881729126,\n",
       " 1.6209956407546997,\n",
       " 0.7457275986671448,\n",
       " 1.7941969633102417,\n",
       " -0.5014255046844482,\n",
       " -0.4702936112880707,\n",
       " 0.2999889552593231,\n",
       " -0.4615684151649475,\n",
       " 0.2130204439163208,\n",
       " -0.6041150689125061,\n",
       " -1.0446796417236328,\n",
       " 0.8531286716461182,\n",
       " 0.2889738380908966,\n",
       " -0.41017770767211914,\n",
       " 0.40733596682548523,\n",
       " 0.8498752117156982,\n",
       " -0.4815526604652405,\n",
       " -0.05672445520758629,\n",
       " 1.1257531642913818,\n",
       " 0.5530678629875183,\n",
       " -0.6035079956054688,\n",
       " -0.9061871767044067,\n",
       " -0.313978910446167,\n",
       " -0.4525693356990814,\n",
       " 0.4740908145904541,\n",
       " 1.8828543424606323,\n",
       " 0.839823842048645,\n",
       " 0.06339561939239502,\n",
       " 0.42471522092819214,\n",
       " -0.7991792559623718,\n",
       " -0.24354656040668488,\n",
       " -0.08587507903575897,\n",
       " 0.5255356431007385,\n",
       " 1.65212082862854,\n",
       " 0.6153823137283325,\n",
       " -0.10616149753332138,\n",
       " -0.5959181189537048,\n",
       " 0.38051939010620117,\n",
       " -0.3146452307701111,\n",
       " 0.3056289851665497,\n",
       " -0.06738386303186417,\n",
       " -0.37013015151023865,\n",
       " 0.0695481076836586,\n",
       " 0.7538078427314758,\n",
       " 0.1446290910243988,\n",
       " -0.14238287508487701,\n",
       " 0.7439709901809692,\n",
       " -0.16604937613010406,\n",
       " 0.28340989351272583,\n",
       " 0.1418670415878296,\n",
       " -0.6043691039085388,\n",
       " 0.47255939245224,\n",
       " 0.45147234201431274,\n",
       " -0.029063289985060692,\n",
       " 0.5504631996154785,\n",
       " -1.4703024625778198,\n",
       " 0.590700089931488,\n",
       " -0.551943838596344,\n",
       " 1.2080543041229248,\n",
       " -0.07406996935606003,\n",
       " 0.3457190692424774,\n",
       " 0.5911201238632202,\n",
       " 0.2587212324142456,\n",
       " -0.5341789126396179,\n",
       " -0.34019187092781067,\n",
       " 0.35935840010643005,\n",
       " 0.23307614028453827,\n",
       " 0.17626918852329254,\n",
       " -0.019390588626265526,\n",
       " -0.513569712638855,\n",
       " -0.6950168013572693,\n",
       " 0.39670637249946594,\n",
       " -0.32831811904907227,\n",
       " -0.09210960566997528,\n",
       " -0.39049777388572693,\n",
       " 0.10523953288793564,\n",
       " -0.32754644751548767,\n",
       " -0.15096436440944672,\n",
       " -0.6131507754325867,\n",
       " 0.6260694861412048,\n",
       " -0.46194812655448914,\n",
       " 1.3703726530075073,\n",
       " -0.05448677018284798,\n",
       " 0.21436777710914612,\n",
       " -0.22135357558727264,\n",
       " 0.4715501368045807,\n",
       " 0.5396367907524109,\n",
       " -0.929953932762146,\n",
       " 0.5716075301170349,\n",
       " 0.4828544557094574,\n",
       " 0.0841643214225769,\n",
       " 0.29254865646362305,\n",
       " 0.6611661911010742,\n",
       " -0.42793336510658264,\n",
       " 0.9107893109321594,\n",
       " -0.42345279455184937,\n",
       " 0.26163044571876526,\n",
       " -0.006446192041039467,\n",
       " -0.682062029838562,\n",
       " -0.6144475936889648,\n",
       " -0.8110193014144897,\n",
       " 0.12693968415260315,\n",
       " -0.035992804914712906,\n",
       " -0.12815117835998535,\n",
       " -0.6912873983383179,\n",
       " -0.4463365077972412,\n",
       " -0.6365297436714172,\n",
       " -0.325644850730896,\n",
       " 0.4100848138332367,\n",
       " 0.5021581649780273,\n",
       " 0.6650241017341614,\n",
       " 0.31957900524139404,\n",
       " 0.5046120882034302,\n",
       " 0.41953837871551514,\n",
       " 0.17391595244407654,\n",
       " 0.5729237794876099,\n",
       " -0.7404175400733948,\n",
       " 1.083732008934021,\n",
       " 0.4706042408943176,\n",
       " -0.8569273948669434,\n",
       " 0.7364718317985535,\n",
       " 0.043919824063777924,\n",
       " 0.5831736326217651,\n",
       " -0.8359079360961914,\n",
       " 0.4667776823043823,\n",
       " -0.5291274785995483,\n",
       " 0.17604446411132812,\n",
       " -0.1723335087299347,\n",
       " 0.6627945303916931,\n",
       " 0.4876698851585388,\n",
       " -0.42754486203193665,\n",
       " 0.18280017375946045,\n",
       " 0.23791545629501343,\n",
       " -0.2807692885398865,\n",
       " 0.41048356890678406,\n",
       " -1.227798581123352,\n",
       " 0.416736364364624,\n",
       " -0.28051456809043884,\n",
       " 0.5369688272476196,\n",
       " 0.4480278789997101,\n",
       " -0.7568938136100769,\n",
       " 0.351581871509552,\n",
       " -0.4363845884799957,\n",
       " -0.56569504737854,\n",
       " -0.4193333685398102,\n",
       " -0.2265438437461853,\n",
       " -0.4169165790081024,\n",
       " 1.6433913707733154,\n",
       " 0.5165605545043945,\n",
       " 1.2344399690628052,\n",
       " -0.1710672229528427,\n",
       " -0.670051097869873,\n",
       " -0.28441178798675537,\n",
       " -0.47408294677734375,\n",
       " 0.6657699942588806,\n",
       " 0.6085067391395569,\n",
       " -0.27822738885879517,\n",
       " -0.4588654041290283,\n",
       " -0.003533013863489032,\n",
       " -0.4516400694847107,\n",
       " -0.8271739482879639,\n",
       " -0.2763958275318146,\n",
       " -0.4756071865558624,\n",
       " 0.9026948809623718,\n",
       " -0.6887316107749939,\n",
       " 0.19703921675682068,\n",
       " 0.371524840593338,\n",
       " 0.5476474165916443,\n",
       " -0.588132381439209,\n",
       " 0.5485528111457825,\n",
       " -0.025209197774529457,\n",
       " 0.17776259779930115,\n",
       " 0.5883907079696655,\n",
       " 0.9542511105537415,\n",
       " -0.19550786912441254,\n",
       " 0.5767303705215454,\n",
       " -0.38101792335510254,\n",
       " 0.894066333770752,\n",
       " 0.6003773212432861,\n",
       " 0.12933894991874695,\n",
       " -0.12973175942897797,\n",
       " 0.7340852618217468,\n",
       " 1.1365326642990112,\n",
       " -0.11541106551885605,\n",
       " 0.0005818433128297329,\n",
       " 0.3900808095932007,\n",
       " -0.3521937131881714,\n",
       " -0.7453104853630066,\n",
       " -0.843396782875061,\n",
       " 2.0049631595611572,\n",
       " 0.5086433291435242,\n",
       " 0.10720249265432358,\n",
       " -0.19485817849636078,\n",
       " -0.13040973246097565,\n",
       " 1.3069099187850952,\n",
       " -0.3727021813392639,\n",
       " -0.8972132205963135,\n",
       " -0.7743067741394043,\n",
       " 0.06186360865831375,\n",
       " -0.5684816837310791,\n",
       " -0.38196107745170593,\n",
       " -0.1583011895418167,\n",
       " 0.6291095018386841,\n",
       " -0.04100421071052551,\n",
       " 0.23841068148612976,\n",
       " -0.44323116540908813,\n",
       " -0.3478519916534424,\n",
       " 0.24041345715522766,\n",
       " -0.11528432369232178,\n",
       " 0.512010931968689,\n",
       " -0.7027880549430847,\n",
       " -0.26351821422576904,\n",
       " 1.5803617238998413,\n",
       " 0.5428001284599304,\n",
       " 0.6764109134674072,\n",
       " -0.40593189001083374,\n",
       " -0.4794858694076538,\n",
       " -1.4393328428268433,\n",
       " -0.1332029104232788,\n",
       " -0.19711509346961975,\n",
       " 0.5660557746887207,\n",
       " 2.41211199760437,\n",
       " -0.4069622755050659,\n",
       " -0.5997989177703857,\n",
       " 0.2205941081047058,\n",
       " 0.01594233512878418,\n",
       " -0.1754879355430603,\n",
       " 0.46526625752449036,\n",
       " -0.09837497770786285,\n",
       " -0.1267167329788208,\n",
       " -0.5437260270118713,\n",
       " 0.3833470940589905,\n",
       " 0.2485227733850479,\n",
       " -0.2818656861782074,\n",
       " 0.7075291872024536,\n",
       " 0.2590961456298828,\n",
       " -0.1661156415939331,\n",
       " -0.20489516854286194,\n",
       " 0.34470710158348083,\n",
       " -0.3705776333808899,\n",
       " -1.2072263956069946,\n",
       " 0.40747442841529846,\n",
       " 0.6107917428016663,\n",
       " -0.6746245622634888,\n",
       " 0.6213241815567017,\n",
       " -0.28560516238212585,\n",
       " 0.8043033480644226,\n",
       " -0.4302259683609009,\n",
       " 0.037923943251371384,\n",
       " -0.2896968722343445,\n",
       " 0.7183030247688293,\n",
       " 1.1090213060379028,\n",
       " 0.49496033787727356,\n",
       " 0.4632558226585388,\n",
       " -0.15906840562820435,\n",
       " 1.0569732189178467,\n",
       " 0.2016904652118683,\n",
       " 0.6162951588630676,\n",
       " 3.092752456665039,\n",
       " -0.6055423617362976,\n",
       " 1.0954960584640503,\n",
       " 0.3729448914527893,\n",
       " 0.36416828632354736,\n",
       " -0.1856941133737564,\n",
       " -1.0001416206359863,\n",
       " -0.3388400971889496,\n",
       " -0.36131009459495544,\n",
       " -0.10973894596099854,\n",
       " -0.5637707710266113,\n",
       " 0.8568241000175476,\n",
       " -0.37655842304229736,\n",
       " -0.30369073152542114,\n",
       " 0.46214190125465393,\n",
       " -0.795710563659668,\n",
       " -0.553276538848877,\n",
       " 0.25746914744377136,\n",
       " 0.17660720646381378,\n",
       " -0.13087686896324158,\n",
       " 0.3261237144470215,\n",
       " 0.5965161919593811,\n",
       " 0.381630539894104,\n",
       " 0.03397746756672859,\n",
       " 0.29085835814476013,\n",
       " 0.07317321747541428,\n",
       " 0.43710827827453613,\n",
       " 0.4119606912136078,\n",
       " -0.5666340589523315,\n",
       " -0.4915906488895416,\n",
       " -0.2433726042509079,\n",
       " 0.5686751008033752,\n",
       " -0.40572237968444824,\n",
       " -0.41166403889656067,\n",
       " -0.724888801574707,\n",
       " 1.737322449684143,\n",
       " 0.43899431824684143,\n",
       " -0.6692835688591003,\n",
       " -0.13841702044010162,\n",
       " -1.0768828392028809,\n",
       " 0.2472541630268097,\n",
       " -0.3121478259563446,\n",
       " 0.6317633986473083,\n",
       " -0.5818067789077759,\n",
       " -0.09949023276567459,\n",
       " -0.3247222900390625,\n",
       " -0.5969464778900146,\n",
       " 0.646721363067627,\n",
       " -0.22549958527088165,\n",
       " -0.06427983939647675,\n",
       " 0.21592658758163452,\n",
       " 0.5775436758995056,\n",
       " -0.47739434242248535,\n",
       " 0.10494987666606903,\n",
       " 0.49988630414009094,\n",
       " 0.214178204536438,\n",
       " -0.7925437688827515,\n",
       " -0.7305238246917725,\n",
       " -0.35628440976142883,\n",
       " -0.4215300679206848,\n",
       " 0.247428297996521,\n",
       " 1.0701441764831543,\n",
       " 0.2319108247756958,\n",
       " -0.929712176322937,\n",
       " -0.4485740661621094,\n",
       " -0.2456568479537964,\n",
       " -0.19406309723854065,\n",
       " -0.6069080829620361,\n",
       " 0.6317859888076782,\n",
       " 0.2913401126861572,\n",
       " 1.3771803379058838,\n",
       " 0.7946559190750122,\n",
       " 0.21495497226715088,\n",
       " -0.34555262327194214,\n",
       " 0.012174321338534355,\n",
       " -0.4975298047065735,\n",
       " 1.3398815393447876,\n",
       " -0.6235169172286987,\n",
       " 0.22019363939762115,\n",
       " -0.4921678304672241,\n",
       " -0.5601614117622375,\n",
       " 0.5701664090156555,\n",
       " -0.5878913998603821,\n",
       " -0.5540899634361267,\n",
       " 0.4181225597858429,\n",
       " 0.4432258605957031,\n",
       " 1.064923882484436,\n",
       " 0.6392338871955872,\n",
       " 1.1705445051193237,\n",
       " -0.3608351945877075,\n",
       " 0.5347874760627747,\n",
       " -0.05412950739264488,\n",
       " -0.7066929340362549,\n",
       " -0.010448958724737167,\n",
       " -0.5361875891685486,\n",
       " -0.74139803647995,\n",
       " -1.1646023988723755,\n",
       " 0.06615038961172104,\n",
       " 0.6839866638183594,\n",
       " -0.1280607134103775,\n",
       " 0.8413481116294861,\n",
       " -0.642802894115448,\n",
       " 0.16385740041732788,\n",
       " 0.3554195463657379,\n",
       " 0.25578421354293823,\n",
       " -0.612321138381958,\n",
       " 0.6221359968185425,\n",
       " -0.4075619578361511,\n",
       " 0.7100242376327515,\n",
       " 0.2920267581939697,\n",
       " -0.024437041953206062,\n",
       " -0.17871925234794617,\n",
       " -0.12526555359363556,\n",
       " 0.46320104598999023,\n",
       " 1.5127395391464233,\n",
       " -0.4590001702308655,\n",
       " 0.02007361501455307,\n",
       " 0.7437392473220825,\n",
       " 0.19756998121738434,\n",
       " -0.11001182347536087,\n",
       " 0.2097586691379547,\n",
       " 1.0980629920959473,\n",
       " -0.24342933297157288,\n",
       " -0.41931647062301636,\n",
       " 0.3787582218647003,\n",
       " -0.14353607594966888,\n",
       " -0.45316094160079956,\n",
       " -0.36516645550727844,\n",
       " -0.13112090528011322,\n",
       " 0.4761456549167633,\n",
       " -0.6979317665100098,\n",
       " 0.61199551820755,\n",
       " 1.0120242834091187,\n",
       " 1.1336756944656372,\n",
       " 0.8354800939559937,\n",
       " -0.5024398565292358,\n",
       " -0.6337370276451111,\n",
       " -0.2351500242948532,\n",
       " 0.732144832611084,\n",
       " 0.45295438170433044,\n",
       " 0.06397061794996262,\n",
       " -0.44009870290756226,\n",
       " 0.5105792880058289,\n",
       " -1.1614545583724976,\n",
       " -1.0735267400741577,\n",
       " -0.26568761467933655,\n",
       " 0.5729519724845886,\n",
       " 0.4267202615737915,\n",
       " -0.11545492708683014,\n",
       " -0.5573402047157288,\n",
       " -0.5693961381912231,\n",
       " 0.7508984804153442,\n",
       " -0.343186616897583,\n",
       " 0.6726167798042297,\n",
       " 0.5032428503036499,\n",
       " -0.5862520337104797,\n",
       " 0.18308521807193756,\n",
       " 1.1169743537902832,\n",
       " 0.10514253377914429,\n",
       " -0.5928729772567749,\n",
       " 0.08929048478603363,\n",
       " -1.0251295566558838,\n",
       " 0.2587083578109741,\n",
       " -0.4920866787433624,\n",
       " 0.8643641471862793,\n",
       " 0.22100761532783508,\n",
       " 0.3082118630409241,\n",
       " -0.3671160638332367,\n",
       " 0.7372104525566101,\n",
       " -0.14425337314605713,\n",
       " 0.45971792936325073,\n",
       " -0.24952536821365356,\n",
       " -0.5813795924186707,\n",
       " 0.33744460344314575,\n",
       " 0.0882067084312439,\n",
       " 0.22561103105545044,\n",
       " 0.7998042106628418,\n",
       " -0.5066999793052673,\n",
       " -0.45244207978248596,\n",
       " 0.6481360793113708]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_python.embed_query(python_chunks[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1b62ac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "af24a85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['97f6ef08-274d-4ab5-b395-7c1031d7d9fb',\n",
       " 'f2198186-3ab8-465d-9873-046f8f0bbb0e',\n",
       " '07e8bc10-0b39-4ff0-ada7-bd092e3f5797',\n",
       " '467d59c9-ea1a-49d7-b41d-e41e1c021868',\n",
       " '321a90d8-8f71-43e5-854b-0609f50dd5cf',\n",
       " 'd0d31a85-5432-4247-b3e3-0df21f4d819a',\n",
       " '1183de97-961b-4d69-9d71-93e479feca67',\n",
       " '6a85ba4a-db1a-49f3-9d49-a92e515f7090',\n",
       " '6a32ee94-70f8-484f-9c3a-144649080fd0',\n",
       " '91ed8d32-1615-4872-9c59-b29ca52e60cd',\n",
       " '174c7cb2-5689-493a-af85-d628269a35ed',\n",
       " 'dd3620d1-f6cc-4240-a2e7-7f2637396fc3',\n",
       " '9c8df319-1ac4-45fc-a688-50d62e07c895',\n",
       " '15034c5c-e032-462c-8394-0258297f705e',\n",
       " 'b8864c80-105a-4385-b4a9-029a3e7174c5',\n",
       " '34bdfdb9-61cc-4d9f-acc7-29ea15f88c23',\n",
       " '793585b7-91e4-41fb-9360-295ecf4776e2',\n",
       " '3bea3df6-58a3-4c2d-8cb1-426750c4ca72',\n",
       " '42c6a900-e14f-46e0-be35-0c6f9145a58a',\n",
       " 'a18a56cc-30a8-4109-bfe9-4f9c08fae88b',\n",
       " 'ef55b695-368e-4e7d-9070-0ee71999d839',\n",
       " 'd6b6a648-4539-4075-8abb-3bf665d422ba',\n",
       " '3b48d321-e060-4713-9bb5-5aa134bbd861',\n",
       " '386329cc-81eb-4ba2-9e9c-08abd4a4c30e',\n",
       " '8aa8001b-5dc5-488c-8924-0ae65710f6f3',\n",
       " '350549d3-e325-4b6e-921f-bd113fc5b70a',\n",
       " 'ca7034a8-42a3-4c0c-8c6b-fd7cf8839199',\n",
       " 'c6ca8509-a7a7-4961-b9ad-04faf2884885',\n",
       " 'cef74889-7d02-4339-a0dc-8aaba19289c0',\n",
       " '4b1d9eea-d27c-4196-9235-4688323436e3',\n",
       " '3f8f6886-a44a-4ba0-99a9-4b65d2c449a6',\n",
       " '79108330-416b-4018-a844-c5c05197668b',\n",
       " '865030a2-5520-4440-9526-b623d8b4cba3',\n",
       " '6ab86475-839e-4b1d-af53-20a9b49d8964',\n",
       " '37377ce0-31b0-44d8-aab2-19c93b6d4985',\n",
       " 'c22ef651-dd57-4e1b-9d05-4934b9e4db18',\n",
       " 'bc5951ad-109b-407a-b331-7207fe1e43be',\n",
       " 'b5b524ae-0d07-40ad-a947-5fc547e88306',\n",
       " 'fe3c460f-47e3-47be-84a7-8f71fb839fc7',\n",
       " '996bb520-d6ea-45c8-963d-e420064d6c29',\n",
       " '7dbbd67f-26e4-4411-9289-9a0846f76c97',\n",
       " '89b454db-2824-4830-8664-ad6c0ce08c5d',\n",
       " 'eb90854e-1994-498b-92dc-b6b5fa50e938',\n",
       " '96679edc-00e1-4e77-99f5-96be861b8250']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_documents(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c6b90531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='467d59c9-ea1a-49d7-b41d-e41e1c021868', metadata={'path': 'README.md', 'sha': 'dd252217715486451a6a90d5cce2af2cb83c5918', 'source': 'https://api.github.com/vanna-ai/vanna/blob/main/README.md'}, page_content='| GitHub | PyPI | Documentation | Gurubase |\\n| ------ | ---- | ------------- | -------- |\\n| [![GitHub](https://img.shields.io/badge/GitHub-vanna-blue?logo=github)](https://github.com/vanna-ai/vanna) | [![PyPI](https://img.shields.io/pypi/v/vanna?logo=pypi)](https://pypi.org/project/vanna/) | [![Documentation](https://img.shields.io/badge/Documentation-vanna-blue?logo=read-the-docs)](https://vanna.ai/docs/) | [![Gurubase](https://img.shields.io/badge/Gurubase-Ask%20Vanna%20Guru-006BFF)](https://gurubase.io/g/vanna) |\\n\\n# Vanna\\nVanna is an MIT-licensed open-source Python RAG (Retrieval-Augmented Generation) framework for SQL generation and related functionality.\\n\\nhttps://github.com/vanna-ai/vanna/assets/7146154/1901f47a-515d-4982-af50-f12761a3b2ce\\n\\n![vanna-quadrants](https://github.com/vanna-ai/vanna/assets/7146154/1c7c88ba-c144-4ecf-a028-cf5ba7344ca2)\\n\\n## How Vanna works'),\n",
       " Document(id='3bea3df6-58a3-4c2d-8cb1-426750c4ca72', metadata={'path': 'README.md', 'sha': 'dd252217715486451a6a90d5cce2af2cb83c5918', 'source': 'https://api.github.com/vanna-ai/vanna/blob/main/README.md'}, page_content=\"## Extending Vanna\\nVanna is designed to connect to any database, LLM, and vector database. There's a [VannaBase](https://github.com/vanna-ai/vanna/blob/main/src/vanna/base/base.py) abstract base class that defines some basic functionality. The package provides implementations for use with OpenAI and ChromaDB. You can easily extend Vanna to use your own LLM or vector database. See the [documentation](https://vanna.ai/docs/) for more details.\\n\\n## Vanna in 100 Seconds\\n\\nhttps://github.com/vanna-ai/vanna/assets/7146154/eb90ee1e-aa05-4740-891a-4fc10e611cab\\n\\n## More resources\\n - [Full Documentation](https://vanna.ai/docs/)\\n - [Website](https://vanna.ai)\\n - [Discord group for support](https://discord.gg/qUZYKHremx)\"),\n",
       " Document(id='321a90d8-8f71-43e5-854b-0609f50dd5cf', metadata={'path': 'README.md', 'sha': 'dd252217715486451a6a90d5cce2af2cb83c5918', 'source': 'https://api.github.com/vanna-ai/vanna/blob/main/README.md'}, page_content='![vanna-quadrants](https://github.com/vanna-ai/vanna/assets/7146154/1c7c88ba-c144-4ecf-a028-cf5ba7344ca2)\\n\\n## How Vanna works\\n\\n![Screen Recording 2024-01-24 at 11 21 37\\u202fAM](https://github.com/vanna-ai/vanna/assets/7146154/1d2718ad-12a8-4a76-afa2-c61754462f93)\\n\\n\\nVanna works in two easy steps - train a RAG \"model\" on your data, and then ask questions which will return SQL queries that can be set up to automatically run on your database.\\n\\n1. **Train a RAG \"model\" on your data**.\\n2. **Ask questions**.\\n\\n![](img/vanna-readme-diagram.png)\\n\\nIf you don\\'t know what RAG is, don\\'t worry -- you don\\'t need to know how this works under the hood to use it. You just need to know that you \"train\" a model, which stores some metadata and then use it to \"ask\" questions.\\n\\nSee the [base class](https://github.com/vanna-ai/vanna/blob/main/src/vanna/base/base.py) for more details on how this works under the hood.'),\n",
       " Document(id='b8864c80-105a-4385-b4a9-029a3e7174c5', metadata={'path': 'README.md', 'sha': 'dd252217715486451a6a90d5cce2af2cb83c5918', 'source': 'https://api.github.com/vanna-ai/vanna/blob/main/README.md'}, page_content=\"You'll also get an automated Plotly chart:\\n![](img/top-10-customers.png)\\n\\n## RAG vs. Fine-Tuning\\nRAG\\n- Portable across LLMs\\n- Easy to remove training data if any of it becomes obsolete\\n- Much cheaper to run than fine-tuning\\n- More future-proof -- if a better LLM comes out, you can just swap it out\\n\\nFine-Tuning\\n- Good if you need to minimize tokens in the prompt\\n- Slow to get started\\n- Expensive to train and run (generally)\\n\\n## Why Vanna?\")]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.similarity_search(\"What is Vanna?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cdc959b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8dd8ea36",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.invoke(\"What is Vanna?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f6e9434f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='467d59c9-ea1a-49d7-b41d-e41e1c021868', metadata={'path': 'README.md', 'sha': 'dd252217715486451a6a90d5cce2af2cb83c5918', 'source': 'https://api.github.com/vanna-ai/vanna/blob/main/README.md'}, page_content='| GitHub | PyPI | Documentation | Gurubase |\\n| ------ | ---- | ------------- | -------- |\\n| [![GitHub](https://img.shields.io/badge/GitHub-vanna-blue?logo=github)](https://github.com/vanna-ai/vanna) | [![PyPI](https://img.shields.io/pypi/v/vanna?logo=pypi)](https://pypi.org/project/vanna/) | [![Documentation](https://img.shields.io/badge/Documentation-vanna-blue?logo=read-the-docs)](https://vanna.ai/docs/) | [![Gurubase](https://img.shields.io/badge/Gurubase-Ask%20Vanna%20Guru-006BFF)](https://gurubase.io/g/vanna) |\\n\\n# Vanna\\nVanna is an MIT-licensed open-source Python RAG (Retrieval-Augmented Generation) framework for SQL generation and related functionality.\\n\\nhttps://github.com/vanna-ai/vanna/assets/7146154/1901f47a-515d-4982-af50-f12761a3b2ce\\n\\n![vanna-quadrants](https://github.com/vanna-ai/vanna/assets/7146154/1c7c88ba-c144-4ecf-a028-cf5ba7344ca2)\\n\\n## How Vanna works'),\n",
       " Document(id='3bea3df6-58a3-4c2d-8cb1-426750c4ca72', metadata={'path': 'README.md', 'sha': 'dd252217715486451a6a90d5cce2af2cb83c5918', 'source': 'https://api.github.com/vanna-ai/vanna/blob/main/README.md'}, page_content=\"## Extending Vanna\\nVanna is designed to connect to any database, LLM, and vector database. There's a [VannaBase](https://github.com/vanna-ai/vanna/blob/main/src/vanna/base/base.py) abstract base class that defines some basic functionality. The package provides implementations for use with OpenAI and ChromaDB. You can easily extend Vanna to use your own LLM or vector database. See the [documentation](https://vanna.ai/docs/) for more details.\\n\\n## Vanna in 100 Seconds\\n\\nhttps://github.com/vanna-ai/vanna/assets/7146154/eb90ee1e-aa05-4740-891a-4fc10e611cab\\n\\n## More resources\\n - [Full Documentation](https://vanna.ai/docs/)\\n - [Website](https://vanna.ai)\\n - [Discord group for support](https://discord.gg/qUZYKHremx)\"),\n",
       " Document(id='321a90d8-8f71-43e5-854b-0609f50dd5cf', metadata={'path': 'README.md', 'sha': 'dd252217715486451a6a90d5cce2af2cb83c5918', 'source': 'https://api.github.com/vanna-ai/vanna/blob/main/README.md'}, page_content='![vanna-quadrants](https://github.com/vanna-ai/vanna/assets/7146154/1c7c88ba-c144-4ecf-a028-cf5ba7344ca2)\\n\\n## How Vanna works\\n\\n![Screen Recording 2024-01-24 at 11 21 37\\u202fAM](https://github.com/vanna-ai/vanna/assets/7146154/1d2718ad-12a8-4a76-afa2-c61754462f93)\\n\\n\\nVanna works in two easy steps - train a RAG \"model\" on your data, and then ask questions which will return SQL queries that can be set up to automatically run on your database.\\n\\n1. **Train a RAG \"model\" on your data**.\\n2. **Ask questions**.\\n\\n![](img/vanna-readme-diagram.png)\\n\\nIf you don\\'t know what RAG is, don\\'t worry -- you don\\'t need to know how this works under the hood to use it. You just need to know that you \"train\" a model, which stores some metadata and then use it to \"ask\" questions.\\n\\nSee the [base class](https://github.com/vanna-ai/vanna/blob/main/src/vanna/base/base.py) for more details on how this works under the hood.'),\n",
       " Document(id='b8864c80-105a-4385-b4a9-029a3e7174c5', metadata={'path': 'README.md', 'sha': 'dd252217715486451a6a90d5cce2af2cb83c5918', 'source': 'https://api.github.com/vanna-ai/vanna/blob/main/README.md'}, page_content=\"You'll also get an automated Plotly chart:\\n![](img/top-10-customers.png)\\n\\n## RAG vs. Fine-Tuning\\nRAG\\n- Portable across LLMs\\n- Easy to remove training data if any of it becomes obsolete\\n- Much cheaper to run than fine-tuning\\n- More future-proof -- if a better LLM comes out, you can just swap it out\\n\\nFine-Tuning\\n- Good if you need to minimize tokens in the prompt\\n- Slow to get started\\n- Expensive to train and run (generally)\\n\\n## Why Vanna?\")]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbedb2b7",
   "metadata": {},
   "source": [
    "## LangGraph Agent Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3e8fae33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ac93b7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langsmith/client.py:280: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6c19a583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "58c53dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END, StateGraph, MessagesState\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from typing import TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8998937c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    api_version=\"2024-10-21\",\n",
    "    azure_deployment=\"gpt-4o\"\n",
    ")\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    answer: str\n",
    "\n",
    "\n",
    "def call_model(state: State, config: RunnableConfig):\n",
    "    # Get the latest message\n",
    "    latest_message = state[\"question\"]\n",
    "    \n",
    "    # Otherwise, call the model with the current state\n",
    "    context = retriever.invoke(latest_message)\n",
    "    messages = prompt.invoke({\"question\": latest_message, \"context\": context})\n",
    "    response = llm.invoke(messages, config)\n",
    "    # Return the response\n",
    "    return {\"answer\": response, \"question\": latest_message}\n",
    "\n",
    "def build_graph(checkpointer: MemorySaver = None):\n",
    "    # Graph\n",
    "    builder = StateGraph(State)\n",
    "    \n",
    "    # Define nodes: these do the work\n",
    "    builder.add_node(\"assistant\", call_model)\n",
    "    #builder.add_node(\"tools\", ToolNode(self.tools))\n",
    "    #builder.add_node(\"tools\", self.tool_node)\n",
    "    #builder.add_node(\"summarize_conversation\", self.summarize_conversation)\n",
    "\n",
    "    # Define edges: these determine the control flow\n",
    "    builder.add_edge(START, \"assistant\")\n",
    "    #builder.add_conditional_edges(\n",
    "    #    \"assistant\",\n",
    "    #    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    #    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    #    self.should_continue,\n",
    "    #    #tools_condition\n",
    "    #    [\"tools\", \"summarize_conversation\", END]\n",
    "    #)\n",
    "    #builder.add_edge(\"tools\", \"assistant\")\n",
    "    builder.add_edge(\"assistant\", END)\n",
    "    \n",
    "    #graph = builder.compile(checkpointer=self.mongodb_saver)\n",
    "    graph = builder.compile(checkpointer=checkpointer)\n",
    "    #graph = builder.compile(checkpointer=self.postgres_saver)\n",
    "    #graph = builder.compile(checkpointer=checkpointer)\n",
    "    return graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d51979f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = build_graph(MemorySaver())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2208e025",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "question = \"What is Vanna?\"\n",
    "response = graph.invoke({\"question\": question}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b8eee32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is Vanna?',\n",
       " 'answer': AIMessage(content='Vanna is an open-source Python framework for Retrieval-Augmented Generation (RAG), focused on SQL generation and related functionalities. It can connect to various databases, large language models (LLMs), and vector databases, and enables training a RAG model on data to generate SQL queries. It is MIT-licensed and designed for flexibility and portability.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 70, 'prompt_tokens': 1333, 'total_tokens': 1403, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ee1d74bde0', 'id': 'chatcmpl-BKnbt88LsemXCGPL6AhPOhTpOJHwH', 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {}}, id='run-0cc4c1c0-af0c-4f20-92b2-9cf05d7e1a96-0', usage_metadata={'input_tokens': 1333, 'output_tokens': 70, 'total_tokens': 1403, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8f130195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Vanna is an open-source Python framework for Retrieval-Augmented Generation (RAG), focused on SQL generation and related functionalities. It can connect to various databases, large language models (LLMs), and vector databases, and enables training a RAG model on data to generate SQL queries. It is MIT-licensed and designed for flexibility and portability.'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"answer\"].content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03539208",
   "metadata": {},
   "source": [
    "### Chroma DB Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c74ecb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import AzureOpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bba58ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = AzureOpenAIEmbeddings(\n",
    "        api_version=\"2024-10-21\",\n",
    "        azure_deployment=\"text-embedding-3-small-1\"\n",
    "    )\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"test-task-collection\",\n",
    "    embedding_function=embedding_model,\n",
    "    persist_directory=\"./chroma_db\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e3e6d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the purpose of the Vanna project?\"\n",
    "results = vector_store.similarity_search(query, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c47406d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='5a56c34c-a297-4390-97a8-23d9cfe2c6c7', metadata={'path': 'README.md', 'sha': 'dd252217715486451a6a90d5cce2af2cb83c5918', 'source': 'https://api.github.com/vanna-ai/vanna/blob/main/README.md'}, page_content='## Why Vanna?'),\n",
       " Document(id='a92a03b5-01a2-466c-a2bb-dbab28de73d6', metadata={'path': 'README.md', 'sha': 'dd252217715486451a6a90d5cce2af2cb83c5918', 'source': 'https://api.github.com/vanna-ai/vanna/blob/main/README.md'}, page_content=\"## Extending Vanna\\nVanna is designed to connect to any database, LLM, and vector database. There's a [VannaBase](https://github.com/vanna-ai/vanna/blob/main/src/vanna/base/base.py) abstract base class that defines some basic functionality. The package provides implementations for use with OpenAI and ChromaDB. You can easily extend Vanna to use your own LLM or vector database. See the [documentation](https://vanna.ai/docs/) for more details.\\n\\n## Vanna in 100 Seconds\\n\\nhttps://github.com/vanna-ai/vanna/assets/7146154/eb90ee1e-aa05-4740-891a-4fc10e611cab\\n\\n## More resources\\n - [Full Documentation](https://vanna.ai/docs/)\\n - [Website](https://vanna.ai)\\n - [Discord group for support](https://discord.gg/qUZYKHremx)\"),\n",
       " Document(id='aee97f75-0408-4c0b-9c3d-6a03d9256eb6', metadata={'path': 'README.md', 'sha': 'dd252217715486451a6a90d5cce2af2cb83c5918', 'source': 'https://api.github.com/vanna-ai/vanna/blob/main/README.md'}, page_content='## How Vanna works\\n\\n![Screen Recording 2024-01-24 at 11 21 37\\u202fAM](https://github.com/vanna-ai/vanna/assets/7146154/1d2718ad-12a8-4a76-afa2-c61754462f93)\\n\\n\\nVanna works in two easy steps - train a RAG \"model\" on your data, and then ask questions which will return SQL queries that can be set up to automatically run on your database.\\n\\n1. **Train a RAG \"model\" on your data**.\\n2. **Ask questions**.\\n\\n![](img/vanna-readme-diagram.png)\\n\\nIf you don\\'t know what RAG is, don\\'t worry -- you don\\'t need to know how this works under the hood to use it. You just need to know that you \"train\" a model, which stores some metadata and then use it to \"ask\" questions.\\n\\nSee the [base class](https://github.com/vanna-ai/vanna/blob/main/src/vanna/base/base.py) for more details on how this works under the hood.'),\n",
       " Document(id='0b71be81-7181-4843-969c-f4d5dc800fd8', metadata={'path': 'README.md', 'sha': 'dd252217715486451a6a90d5cce2af2cb83c5918', 'source': 'https://api.github.com/vanna-ai/vanna/blob/main/README.md'}, page_content='| GitHub | PyPI | Documentation | Gurubase |\\n| ------ | ---- | ------------- | -------- |\\n| [![GitHub](https://img.shields.io/badge/GitHub-vanna-blue?logo=github)](https://github.com/vanna-ai/vanna) | [![PyPI](https://img.shields.io/pypi/v/vanna?logo=pypi)](https://pypi.org/project/vanna/) | [![Documentation](https://img.shields.io/badge/Documentation-vanna-blue?logo=read-the-docs)](https://vanna.ai/docs/) | [![Gurubase](https://img.shields.io/badge/Gurubase-Ask%20Vanna%20Guru-006BFF)](https://gurubase.io/g/vanna) |\\n\\n# Vanna\\nVanna is an MIT-licensed open-source Python RAG (Retrieval-Augmented Generation) framework for SQL generation and related functionality.\\n\\nhttps://github.com/vanna-ai/vanna/assets/7146154/1901f47a-515d-4982-af50-f12761a3b2ce\\n\\n![vanna-quadrants](https://github.com/vanna-ai/vanna/assets/7146154/1c7c88ba-c144-4ecf-a028-cf5ba7344ca2)'),\n",
       " Document(id='72c89efa-4ec6-45bb-a7a0-c9bb1495c467', metadata={'path': 'src/vanna/base/base.py', 'sha': '16c6469dcbb0f3a99d27de22a1c391e6456e297f', 'source': 'https://api.github.com/vanna-ai/vanna/blob/main/src/vanna/base/base.py'}, page_content=\"# Open-Source and Extending\\n\\nVanna.AI is open-source and extensible. If you'd like to use Vanna without the servers, see an example [here](https://vanna.ai/docs/postgres-ollama-chromadb/).\")]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f926b1",
   "metadata": {},
   "source": [
    "### List Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9e2f566",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"[Document(id='61e6653a-2ee8-4dca-90f5-2e974cd1c70f', metadata={'path': 'src/vanna/chromadb/chromadb_vector.py', 'sha': '7fa682f48c2977a2e1440ffec11512182ecd1a1c', 'source': 'https://api.github.com/vanna-ai/vanna/blob/main/src/vanna/chromadb/chromadb_vector.py'}, page_content='if curr_client == \\\"persistent\\\":\\\\n            self.chroma_client = chromadb.PersistentClient(\\\\n                path=path, settings=Settings(anonymized_telemetry=False)\\\\n            )\\\\n        elif curr_client == \\\"in-memory\\\":\\\\n            self.chroma_client = chromadb.EphemeralClient(\\\\n                settings=Settings(anonymized_telemetry=False)\\\\n            )\\\\n        elif isinstance(curr_client, chromadb.api.client.Client):\\\\n            # allow providing client directly'), Document(id='e02d2657-d2e1-4f05-87e9-a3decc87ee86', metadata={'path': 'src/vanna/base/base.py', 'sha': '16c6469dcbb0f3a99d27de22a1c391e6456e297f', 'source': 'https://api.github.com/vanna-ai/vanna/blob/main/src/vanna/base/base.py'}, page_content='uses the OpenAI API to generate SQL and Plotly code. `vanna.chromadb_vector.ChromaDB_VectorStore` uses ChromaDB to store training data and generate embeddings.'), Document(id='f61a8a14-29c7-43e4-a6ec-ea580584c3bf', metadata={'path': 'src/vanna/chromadb/chromadb_vector.py', 'sha': '7fa682f48c2977a2e1440ffec11512182ecd1a1c', 'source': 'https://api.github.com/vanna-ai/vanna/blob/main/src/vanna/chromadb/chromadb_vector.py'}, page_content=')\\\\n        self.sql_collection = self.chroma_client.get_or_create_collection(\\\\n            name=\\\"sql\\\",\\\\n            embedding_function=self.embedding_function,\\\\n            metadata=collection_metadata,\\\\n        )'), Document(id='be28c938-3ef2-4c01-bfc3-d0f2377c7f76', metadata={'path': 'src/vanna/base/base.py', 'sha': '16c6469dcbb0f3a99d27de22a1c391e6456e297f', 'source': 'https://api.github.com/vanna-ai/vanna/blob/main/src/vanna/base/base.py'}, page_content='subgraph ChromaDB_VectorStore\\\\n        generate_embedding\\\\n        add_question_sql\\\\n        add_ddl\\\\n        add_documentation\\\\n        get_similar_question_sql\\\\n        get_related_ddl\\\\n        get_related_documentation\\\\n    end\\\\n```\\\\n\\\\n\\\"\\\"\\\"\\\\n\\\\nimport json\\\\nimport os\\\\nimport re\\\\nimport sqlite3\\\\nimport traceback\\\\nfrom abc import ABC, abstractmethod\\\\nfrom typing import List, Tuple, Union\\\\nfrom urllib.parse import urlparse'), Document(id='bf3bd06f-8a33-45c3-bdcc-bb435b6ec951', metadata={'path': 'src/vanna/chromadb/chromadb_vector.py', 'sha': '7fa682f48c2977a2e1440ffec11512182ecd1a1c', 'source': 'https://api.github.com/vanna-ai/vanna/blob/main/src/vanna/chromadb/chromadb_vector.py'}, page_content='self.documentation_collection = self.chroma_client.get_or_create_collection(\\\\n            name=\\\"documentation\\\",\\\\n            embedding_function=self.embedding_function,\\\\n            metadata=collection_metadata,\\\\n        )\\\\n        self.ddl_collection = self.chroma_client.get_or_create_collection(\\\\n            name=\\\"ddl\\\",\\\\n            embedding_function=self.embedding_function,\\\\n            metadata=collection_metadata,\\\\n        )')]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b4fbc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b107d3d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "malformed node or string on line 1: <ast.Call object at 0x169f05f10>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mast\u001b[49m\u001b[43m.\u001b[49m\u001b[43mliteral_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ast.py:112\u001b[39m, in \u001b[36mliteral_eval\u001b[39m\u001b[34m(node_or_string)\u001b[39m\n\u001b[32m    110\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m left - right\n\u001b[32m    111\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _convert_signed_num(node)\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_or_string\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ast.py:92\u001b[39m, in \u001b[36mliteral_eval.<locals>._convert\u001b[39m\u001b[34m(node)\u001b[39m\n\u001b[32m     90\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(_convert, node.elts))\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, List):\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_convert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m.\u001b[49m\u001b[43melts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, Set):\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mmap\u001b[39m(_convert, node.elts))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ast.py:111\u001b[39m, in \u001b[36mliteral_eval.<locals>._convert\u001b[39m\u001b[34m(node)\u001b[39m\n\u001b[32m    109\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    110\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m left - right\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert_signed_num\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ast.py:85\u001b[39m, in \u001b[36mliteral_eval.<locals>._convert_signed_num\u001b[39m\u001b[34m(node)\u001b[39m\n\u001b[32m     83\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     84\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m - operand\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert_num\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ast.py:76\u001b[39m, in \u001b[36mliteral_eval.<locals>._convert_num\u001b[39m\u001b[34m(node)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_convert_num\u001b[39m(node):\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, Constant) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(node.value) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mcomplex\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m         \u001b[43m_raise_malformed_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m node.value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ast.py:73\u001b[39m, in \u001b[36mliteral_eval.<locals>._raise_malformed_node\u001b[39m\u001b[34m(node)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m lno := \u001b[38;5;28mgetattr\u001b[39m(node, \u001b[33m'\u001b[39m\u001b[33mlineno\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     72\u001b[39m     msg += \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m on line \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlno\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg + \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: malformed node or string on line 1: <ast.Call object at 0x169f05f10>"
     ]
    }
   ],
   "source": [
    "ast.literal_eval(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f1371b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
